{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 데이터 로드\n",
        "data_path = '/content/week5_test.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# 입력 및 출력 변수 분리\n",
        "X = data[['GyroX', 'GyroY', 'GyroZ', 'Temperature', 'Heartbeat']].values\n",
        "y = data['Label'].values\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# 훈련 및 테스트 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 정규화\n",
        "X_train_mean = X_train.mean(axis=0)\n",
        "X_train_std = X_train.std(axis=0)\n",
        "X_train_normalized = (X_train - X_train_mean) / X_train_std\n",
        "X_test_normalized = (X_test - X_train_mean) / X_train_std\n",
        "\n",
        "# 입력 데이터 형태 조정\n",
        "X_train_reshaped = X_train_normalized.reshape((X_train_normalized.shape[0], X_train_normalized.shape[1], 1))\n",
        "X_test_reshaped = X_test_normalized.reshape((X_test_normalized.shape[0], X_test_normalized.shape[1], 1))\n",
        "\n",
        "# CNN-LSTM 모델 구성\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_normalized.shape[1], 1)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4dU6Y4RQUQ9",
        "outputId": "0d130f91-6d59-4522-f9f6-ab450bc16f67"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "17/17 [==============================] - 5s 67ms/step - loss: 1.7541 - accuracy: 0.3996 - val_loss: 1.6500 - val_accuracy: 0.6370\n",
            "Epoch 2/10\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 1.6254 - accuracy: 0.5149 - val_loss: 1.4401 - val_accuracy: 0.6370\n",
            "Epoch 3/10\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 1.4621 - accuracy: 0.5149 - val_loss: 1.2153 - val_accuracy: 0.6370\n",
            "Epoch 4/10\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 1.3536 - accuracy: 0.5149 - val_loss: 1.1040 - val_accuracy: 0.6370\n",
            "Epoch 5/10\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 1.2752 - accuracy: 0.5149 - val_loss: 1.0600 - val_accuracy: 0.6444\n",
            "Epoch 6/10\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 1.2153 - accuracy: 0.5260 - val_loss: 1.0064 - val_accuracy: 0.6667\n",
            "Epoch 7/10\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 1.1564 - accuracy: 0.5651 - val_loss: 0.9544 - val_accuracy: 0.6963\n",
            "Epoch 8/10\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 1.0951 - accuracy: 0.6115 - val_loss: 0.8974 - val_accuracy: 0.7037\n",
            "Epoch 9/10\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 1.0358 - accuracy: 0.6320 - val_loss: 0.8597 - val_accuracy: 0.7111\n",
            "Epoch 10/10\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.9826 - accuracy: 0.6338 - val_loss: 0.8196 - val_accuracy: 0.7111\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faabd077670>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dW4L7bdae8tX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 데이터 로드\n",
        "data_path = '/content/week5_test.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# 입력 및 출력 변수 분리\n",
        "X = data[['GyroX', 'GyroY', 'GyroZ', 'Temperature', 'Heartbeat']].values\n",
        "y = data['Label'].values\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# 훈련 및 테스트 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 정규화\n",
        "X_train_mean = X_train.mean(axis=0)\n",
        "X_train_std = X_train.std(axis=0)\n",
        "X_train_normalized = (X_train - X_train_mean) / X_train_std\n",
        "X_test_normalized = (X_test - X_train_mean) / X_train_std\n",
        "\n",
        "# 입력 데이터 형태 조정\n",
        "X_train_reshaped = X_train_normalized.reshape((X_train_normalized.shape[0], X_train_normalized.shape[1], 1))\n",
        "X_test_reshaped = X_test_normalized.reshape((X_test_normalized.shape[0], X_test_normalized.shape[1], 1))\n",
        "\n",
        "# CNN-LSTM 모델 구성\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_normalized.shape[1], 1)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(X_train_reshaped, y_train, epochs=500, batch_size=32, validation_data=(X_test_reshaped, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d83fe04a-2c18-4a64-bada-0f9ee53c589f",
        "id": "Tnzb7Lp2e_Hx"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "17/17 [==============================] - 5s 62ms/step - loss: 1.7399 - accuracy: 0.4331 - val_loss: 1.6172 - val_accuracy: 0.6370\n",
            "Epoch 2/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 1.5954 - accuracy: 0.5149 - val_loss: 1.3896 - val_accuracy: 0.6370\n",
            "Epoch 3/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 1.4477 - accuracy: 0.5149 - val_loss: 1.1996 - val_accuracy: 0.6370\n",
            "Epoch 4/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 1.3463 - accuracy: 0.5149 - val_loss: 1.1261 - val_accuracy: 0.6370\n",
            "Epoch 5/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 1.2889 - accuracy: 0.5149 - val_loss: 1.0868 - val_accuracy: 0.6370\n",
            "Epoch 6/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 1.2385 - accuracy: 0.5149 - val_loss: 1.0412 - val_accuracy: 0.6370\n",
            "Epoch 7/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 1.1896 - accuracy: 0.5316 - val_loss: 0.9940 - val_accuracy: 0.6741\n",
            "Epoch 8/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 1.1325 - accuracy: 0.5781 - val_loss: 0.9394 - val_accuracy: 0.6889\n",
            "Epoch 9/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 1.0756 - accuracy: 0.6134 - val_loss: 0.8978 - val_accuracy: 0.7037\n",
            "Epoch 10/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 1.0173 - accuracy: 0.6301 - val_loss: 0.8469 - val_accuracy: 0.7037\n",
            "Epoch 11/500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.9650 - accuracy: 0.6506 - val_loss: 0.8188 - val_accuracy: 0.7333\n",
            "Epoch 12/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.9267 - accuracy: 0.6580 - val_loss: 0.7897 - val_accuracy: 0.7333\n",
            "Epoch 13/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.8884 - accuracy: 0.6599 - val_loss: 0.7786 - val_accuracy: 0.7704\n",
            "Epoch 14/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.8608 - accuracy: 0.7026 - val_loss: 0.7472 - val_accuracy: 0.7778\n",
            "Epoch 15/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.8377 - accuracy: 0.7268 - val_loss: 0.7319 - val_accuracy: 0.7778\n",
            "Epoch 16/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.8122 - accuracy: 0.7305 - val_loss: 0.7247 - val_accuracy: 0.7630\n",
            "Epoch 17/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.7934 - accuracy: 0.7342 - val_loss: 0.7088 - val_accuracy: 0.7778\n",
            "Epoch 18/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.7752 - accuracy: 0.7342 - val_loss: 0.6926 - val_accuracy: 0.7704\n",
            "Epoch 19/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.7575 - accuracy: 0.7342 - val_loss: 0.6733 - val_accuracy: 0.7704\n",
            "Epoch 20/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.7444 - accuracy: 0.7361 - val_loss: 0.6695 - val_accuracy: 0.7852\n",
            "Epoch 21/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.7237 - accuracy: 0.7509 - val_loss: 0.6389 - val_accuracy: 0.7926\n",
            "Epoch 22/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.7087 - accuracy: 0.7416 - val_loss: 0.6362 - val_accuracy: 0.8000\n",
            "Epoch 23/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.6905 - accuracy: 0.7621 - val_loss: 0.6223 - val_accuracy: 0.7852\n",
            "Epoch 24/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.6790 - accuracy: 0.7491 - val_loss: 0.6086 - val_accuracy: 0.7926\n",
            "Epoch 25/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.6640 - accuracy: 0.7584 - val_loss: 0.5934 - val_accuracy: 0.7926\n",
            "Epoch 26/500\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.6616 - accuracy: 0.7639 - val_loss: 0.5784 - val_accuracy: 0.7926\n",
            "Epoch 27/500\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.6418 - accuracy: 0.7732 - val_loss: 0.5873 - val_accuracy: 0.7778\n",
            "Epoch 28/500\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.6299 - accuracy: 0.7714 - val_loss: 0.5688 - val_accuracy: 0.7852\n",
            "Epoch 29/500\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.6238 - accuracy: 0.7770 - val_loss: 0.5551 - val_accuracy: 0.8148\n",
            "Epoch 30/500\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.6127 - accuracy: 0.7751 - val_loss: 0.5513 - val_accuracy: 0.8148\n",
            "Epoch 31/500\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.6029 - accuracy: 0.7900 - val_loss: 0.5434 - val_accuracy: 0.8222\n",
            "Epoch 32/500\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.5942 - accuracy: 0.7900 - val_loss: 0.5418 - val_accuracy: 0.8148\n",
            "Epoch 33/500\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.5852 - accuracy: 0.7937 - val_loss: 0.5359 - val_accuracy: 0.8222\n",
            "Epoch 34/500\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.5786 - accuracy: 0.7937 - val_loss: 0.5305 - val_accuracy: 0.8222\n",
            "Epoch 35/500\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.5752 - accuracy: 0.8030 - val_loss: 0.5319 - val_accuracy: 0.8148\n",
            "Epoch 36/500\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.5638 - accuracy: 0.7993 - val_loss: 0.5282 - val_accuracy: 0.8148\n",
            "Epoch 37/500\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.5589 - accuracy: 0.8067 - val_loss: 0.5226 - val_accuracy: 0.8148\n",
            "Epoch 38/500\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.5574 - accuracy: 0.8030 - val_loss: 0.5201 - val_accuracy: 0.8370\n",
            "Epoch 39/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5499 - accuracy: 0.8086 - val_loss: 0.5185 - val_accuracy: 0.8222\n",
            "Epoch 40/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5449 - accuracy: 0.8067 - val_loss: 0.5108 - val_accuracy: 0.8222\n",
            "Epoch 41/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5398 - accuracy: 0.8104 - val_loss: 0.5149 - val_accuracy: 0.8222\n",
            "Epoch 42/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5377 - accuracy: 0.8123 - val_loss: 0.5024 - val_accuracy: 0.8370\n",
            "Epoch 43/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5296 - accuracy: 0.8141 - val_loss: 0.5081 - val_accuracy: 0.8222\n",
            "Epoch 44/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5273 - accuracy: 0.8104 - val_loss: 0.5112 - val_accuracy: 0.8296\n",
            "Epoch 45/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5275 - accuracy: 0.8178 - val_loss: 0.5060 - val_accuracy: 0.8370\n",
            "Epoch 46/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5194 - accuracy: 0.8160 - val_loss: 0.5033 - val_accuracy: 0.8296\n",
            "Epoch 47/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5161 - accuracy: 0.8197 - val_loss: 0.5012 - val_accuracy: 0.8444\n",
            "Epoch 48/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5111 - accuracy: 0.8216 - val_loss: 0.4957 - val_accuracy: 0.8444\n",
            "Epoch 49/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5091 - accuracy: 0.8141 - val_loss: 0.5026 - val_accuracy: 0.8222\n",
            "Epoch 50/500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.5034 - accuracy: 0.8178 - val_loss: 0.4959 - val_accuracy: 0.8296\n",
            "Epoch 51/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5067 - accuracy: 0.8160 - val_loss: 0.4974 - val_accuracy: 0.8444\n",
            "Epoch 52/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5005 - accuracy: 0.8271 - val_loss: 0.4924 - val_accuracy: 0.8519\n",
            "Epoch 53/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4936 - accuracy: 0.8253 - val_loss: 0.4975 - val_accuracy: 0.8296\n",
            "Epoch 54/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4943 - accuracy: 0.8253 - val_loss: 0.4959 - val_accuracy: 0.8370\n",
            "Epoch 55/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4908 - accuracy: 0.8309 - val_loss: 0.4935 - val_accuracy: 0.8444\n",
            "Epoch 56/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4863 - accuracy: 0.8253 - val_loss: 0.4908 - val_accuracy: 0.8370\n",
            "Epoch 57/500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4850 - accuracy: 0.8290 - val_loss: 0.4921 - val_accuracy: 0.8444\n",
            "Epoch 58/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4846 - accuracy: 0.8346 - val_loss: 0.4974 - val_accuracy: 0.8370\n",
            "Epoch 59/500\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.4801 - accuracy: 0.8346 - val_loss: 0.4876 - val_accuracy: 0.8444\n",
            "Epoch 60/500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4755 - accuracy: 0.8327 - val_loss: 0.4906 - val_accuracy: 0.8370\n",
            "Epoch 61/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4735 - accuracy: 0.8309 - val_loss: 0.4916 - val_accuracy: 0.8296\n",
            "Epoch 62/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4738 - accuracy: 0.8327 - val_loss: 0.4921 - val_accuracy: 0.8222\n",
            "Epoch 63/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4721 - accuracy: 0.8383 - val_loss: 0.4883 - val_accuracy: 0.8370\n",
            "Epoch 64/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4654 - accuracy: 0.8346 - val_loss: 0.4869 - val_accuracy: 0.8370\n",
            "Epoch 65/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4662 - accuracy: 0.8327 - val_loss: 0.4880 - val_accuracy: 0.8296\n",
            "Epoch 66/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4659 - accuracy: 0.8383 - val_loss: 0.4878 - val_accuracy: 0.8370\n",
            "Epoch 67/500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4612 - accuracy: 0.8346 - val_loss: 0.4824 - val_accuracy: 0.8370\n",
            "Epoch 68/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4566 - accuracy: 0.8401 - val_loss: 0.4838 - val_accuracy: 0.8370\n",
            "Epoch 69/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4567 - accuracy: 0.8309 - val_loss: 0.4884 - val_accuracy: 0.8222\n",
            "Epoch 70/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4495 - accuracy: 0.8401 - val_loss: 0.4851 - val_accuracy: 0.8222\n",
            "Epoch 71/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4498 - accuracy: 0.8420 - val_loss: 0.4875 - val_accuracy: 0.8222\n",
            "Epoch 72/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4472 - accuracy: 0.8401 - val_loss: 0.4797 - val_accuracy: 0.8370\n",
            "Epoch 73/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4474 - accuracy: 0.8364 - val_loss: 0.4891 - val_accuracy: 0.8222\n",
            "Epoch 74/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4446 - accuracy: 0.8420 - val_loss: 0.4863 - val_accuracy: 0.8222\n",
            "Epoch 75/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4408 - accuracy: 0.8439 - val_loss: 0.4840 - val_accuracy: 0.8222\n",
            "Epoch 76/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4370 - accuracy: 0.8439 - val_loss: 0.4812 - val_accuracy: 0.8296\n",
            "Epoch 77/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4387 - accuracy: 0.8420 - val_loss: 0.4903 - val_accuracy: 0.8222\n",
            "Epoch 78/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4380 - accuracy: 0.8439 - val_loss: 0.4863 - val_accuracy: 0.8370\n",
            "Epoch 79/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4347 - accuracy: 0.8457 - val_loss: 0.4812 - val_accuracy: 0.8296\n",
            "Epoch 80/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4299 - accuracy: 0.8476 - val_loss: 0.4831 - val_accuracy: 0.8222\n",
            "Epoch 81/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4258 - accuracy: 0.8550 - val_loss: 0.4805 - val_accuracy: 0.8296\n",
            "Epoch 82/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4230 - accuracy: 0.8476 - val_loss: 0.4891 - val_accuracy: 0.8296\n",
            "Epoch 83/500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4222 - accuracy: 0.8550 - val_loss: 0.4828 - val_accuracy: 0.8370\n",
            "Epoch 84/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4209 - accuracy: 0.8476 - val_loss: 0.4901 - val_accuracy: 0.8148\n",
            "Epoch 85/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4164 - accuracy: 0.8550 - val_loss: 0.4805 - val_accuracy: 0.8444\n",
            "Epoch 86/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.8569 - val_loss: 0.4740 - val_accuracy: 0.8370\n",
            "Epoch 87/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4136 - accuracy: 0.8494 - val_loss: 0.4876 - val_accuracy: 0.8148\n",
            "Epoch 88/500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4124 - accuracy: 0.8513 - val_loss: 0.4801 - val_accuracy: 0.8444\n",
            "Epoch 89/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8587 - val_loss: 0.4850 - val_accuracy: 0.8296\n",
            "Epoch 90/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4087 - accuracy: 0.8625 - val_loss: 0.4845 - val_accuracy: 0.8296\n",
            "Epoch 91/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4067 - accuracy: 0.8625 - val_loss: 0.4869 - val_accuracy: 0.8296\n",
            "Epoch 92/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4022 - accuracy: 0.8699 - val_loss: 0.4773 - val_accuracy: 0.8519\n",
            "Epoch 93/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4016 - accuracy: 0.8569 - val_loss: 0.4874 - val_accuracy: 0.8222\n",
            "Epoch 94/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.3993 - accuracy: 0.8587 - val_loss: 0.4797 - val_accuracy: 0.8370\n",
            "Epoch 95/500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.3990 - accuracy: 0.8662 - val_loss: 0.4784 - val_accuracy: 0.8370\n",
            "Epoch 96/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.3944 - accuracy: 0.8736 - val_loss: 0.4959 - val_accuracy: 0.8222\n",
            "Epoch 97/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4014 - accuracy: 0.8662 - val_loss: 0.4819 - val_accuracy: 0.8296\n",
            "Epoch 98/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.3978 - accuracy: 0.8717 - val_loss: 0.4854 - val_accuracy: 0.8296\n",
            "Epoch 99/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.3897 - accuracy: 0.8494 - val_loss: 0.4841 - val_accuracy: 0.8296\n",
            "Epoch 100/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.3905 - accuracy: 0.8699 - val_loss: 0.4845 - val_accuracy: 0.8296\n",
            "Epoch 101/500\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.3825 - accuracy: 0.8662 - val_loss: 0.4833 - val_accuracy: 0.8370\n",
            "Epoch 102/500\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.3799 - accuracy: 0.8662 - val_loss: 0.4844 - val_accuracy: 0.8296\n",
            "Epoch 103/500\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.3824 - accuracy: 0.8680 - val_loss: 0.4917 - val_accuracy: 0.8296\n",
            "Epoch 104/500\n",
            "17/17 [==============================] - 1s 33ms/step - loss: 0.3881 - accuracy: 0.8699 - val_loss: 0.4822 - val_accuracy: 0.8296\n",
            "Epoch 105/500\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.3766 - accuracy: 0.8699 - val_loss: 0.4845 - val_accuracy: 0.8370\n",
            "Epoch 106/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.3737 - accuracy: 0.8736 - val_loss: 0.4878 - val_accuracy: 0.8296\n",
            "Epoch 107/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.3841 - accuracy: 0.8680 - val_loss: 0.4721 - val_accuracy: 0.8519\n",
            "Epoch 108/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.3732 - accuracy: 0.8569 - val_loss: 0.4905 - val_accuracy: 0.8370\n",
            "Epoch 109/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.3675 - accuracy: 0.8773 - val_loss: 0.4747 - val_accuracy: 0.8370\n",
            "Epoch 110/500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.3705 - accuracy: 0.8643 - val_loss: 0.4989 - val_accuracy: 0.8296\n",
            "Epoch 111/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.3704 - accuracy: 0.8680 - val_loss: 0.4920 - val_accuracy: 0.8222\n",
            "Epoch 112/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.3590 - accuracy: 0.8755 - val_loss: 0.4870 - val_accuracy: 0.8296\n",
            "Epoch 113/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.3567 - accuracy: 0.8736 - val_loss: 0.4976 - val_accuracy: 0.8222\n",
            "Epoch 114/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.3581 - accuracy: 0.8773 - val_loss: 0.4836 - val_accuracy: 0.8296\n",
            "Epoch 115/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.3566 - accuracy: 0.8699 - val_loss: 0.4933 - val_accuracy: 0.8222\n",
            "Epoch 116/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.3500 - accuracy: 0.8810 - val_loss: 0.4817 - val_accuracy: 0.8222\n",
            "Epoch 117/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3509 - accuracy: 0.8829 - val_loss: 0.4877 - val_accuracy: 0.8222\n",
            "Epoch 118/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3500 - accuracy: 0.8736 - val_loss: 0.4909 - val_accuracy: 0.8074\n",
            "Epoch 119/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3541 - accuracy: 0.8680 - val_loss: 0.4939 - val_accuracy: 0.8222\n",
            "Epoch 120/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.3427 - accuracy: 0.8792 - val_loss: 0.4823 - val_accuracy: 0.8222\n",
            "Epoch 121/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3413 - accuracy: 0.8792 - val_loss: 0.4939 - val_accuracy: 0.8222\n",
            "Epoch 122/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3375 - accuracy: 0.8810 - val_loss: 0.4910 - val_accuracy: 0.8370\n",
            "Epoch 123/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3396 - accuracy: 0.8736 - val_loss: 0.5026 - val_accuracy: 0.8222\n",
            "Epoch 124/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.3369 - accuracy: 0.8810 - val_loss: 0.4953 - val_accuracy: 0.8222\n",
            "Epoch 125/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3319 - accuracy: 0.8829 - val_loss: 0.5010 - val_accuracy: 0.8074\n",
            "Epoch 126/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3344 - accuracy: 0.8717 - val_loss: 0.5008 - val_accuracy: 0.8074\n",
            "Epoch 127/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.3281 - accuracy: 0.8885 - val_loss: 0.5017 - val_accuracy: 0.8148\n",
            "Epoch 128/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3309 - accuracy: 0.8848 - val_loss: 0.5031 - val_accuracy: 0.8074\n",
            "Epoch 129/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3288 - accuracy: 0.8848 - val_loss: 0.5038 - val_accuracy: 0.8000\n",
            "Epoch 130/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3289 - accuracy: 0.8866 - val_loss: 0.5028 - val_accuracy: 0.8148\n",
            "Epoch 131/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3239 - accuracy: 0.8848 - val_loss: 0.4907 - val_accuracy: 0.8296\n",
            "Epoch 132/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3260 - accuracy: 0.8755 - val_loss: 0.4999 - val_accuracy: 0.8148\n",
            "Epoch 133/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3281 - accuracy: 0.8773 - val_loss: 0.4984 - val_accuracy: 0.8296\n",
            "Epoch 134/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3178 - accuracy: 0.8885 - val_loss: 0.5118 - val_accuracy: 0.8148\n",
            "Epoch 135/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3202 - accuracy: 0.8792 - val_loss: 0.5045 - val_accuracy: 0.8148\n",
            "Epoch 136/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3194 - accuracy: 0.8810 - val_loss: 0.5126 - val_accuracy: 0.8000\n",
            "Epoch 137/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3108 - accuracy: 0.8866 - val_loss: 0.4983 - val_accuracy: 0.8000\n",
            "Epoch 138/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3142 - accuracy: 0.8866 - val_loss: 0.5045 - val_accuracy: 0.8222\n",
            "Epoch 139/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3126 - accuracy: 0.8792 - val_loss: 0.5053 - val_accuracy: 0.8074\n",
            "Epoch 140/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.3103 - accuracy: 0.8810 - val_loss: 0.5165 - val_accuracy: 0.8000\n",
            "Epoch 141/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3086 - accuracy: 0.8996 - val_loss: 0.4994 - val_accuracy: 0.8222\n",
            "Epoch 142/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3075 - accuracy: 0.8810 - val_loss: 0.5271 - val_accuracy: 0.8074\n",
            "Epoch 143/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3079 - accuracy: 0.8885 - val_loss: 0.5128 - val_accuracy: 0.8000\n",
            "Epoch 144/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3033 - accuracy: 0.8885 - val_loss: 0.5091 - val_accuracy: 0.8000\n",
            "Epoch 145/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3036 - accuracy: 0.8922 - val_loss: 0.5217 - val_accuracy: 0.8148\n",
            "Epoch 146/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3009 - accuracy: 0.8866 - val_loss: 0.5046 - val_accuracy: 0.8148\n",
            "Epoch 147/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2988 - accuracy: 0.8922 - val_loss: 0.5422 - val_accuracy: 0.7926\n",
            "Epoch 148/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2972 - accuracy: 0.8903 - val_loss: 0.5140 - val_accuracy: 0.8148\n",
            "Epoch 149/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2995 - accuracy: 0.8922 - val_loss: 0.5328 - val_accuracy: 0.8000\n",
            "Epoch 150/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2956 - accuracy: 0.8941 - val_loss: 0.5232 - val_accuracy: 0.8074\n",
            "Epoch 151/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.2906 - accuracy: 0.8866 - val_loss: 0.5108 - val_accuracy: 0.8148\n",
            "Epoch 152/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2925 - accuracy: 0.8903 - val_loss: 0.5305 - val_accuracy: 0.8074\n",
            "Epoch 153/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2919 - accuracy: 0.8866 - val_loss: 0.5213 - val_accuracy: 0.8148\n",
            "Epoch 154/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2938 - accuracy: 0.8848 - val_loss: 0.5137 - val_accuracy: 0.8148\n",
            "Epoch 155/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.2891 - accuracy: 0.8922 - val_loss: 0.5366 - val_accuracy: 0.8000\n",
            "Epoch 156/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.2894 - accuracy: 0.8848 - val_loss: 0.5178 - val_accuracy: 0.8074\n",
            "Epoch 157/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.2865 - accuracy: 0.8903 - val_loss: 0.5192 - val_accuracy: 0.8222\n",
            "Epoch 158/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2877 - accuracy: 0.8959 - val_loss: 0.5223 - val_accuracy: 0.8296\n",
            "Epoch 159/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.2849 - accuracy: 0.8903 - val_loss: 0.5273 - val_accuracy: 0.8074\n",
            "Epoch 160/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2852 - accuracy: 0.8978 - val_loss: 0.5249 - val_accuracy: 0.8148\n",
            "Epoch 161/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2833 - accuracy: 0.8885 - val_loss: 0.5351 - val_accuracy: 0.8074\n",
            "Epoch 162/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2876 - accuracy: 0.8941 - val_loss: 0.5155 - val_accuracy: 0.8222\n",
            "Epoch 163/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2800 - accuracy: 0.8903 - val_loss: 0.5314 - val_accuracy: 0.8148\n",
            "Epoch 164/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2767 - accuracy: 0.8848 - val_loss: 0.5362 - val_accuracy: 0.8000\n",
            "Epoch 165/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2791 - accuracy: 0.8978 - val_loss: 0.5358 - val_accuracy: 0.8074\n",
            "Epoch 166/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2729 - accuracy: 0.8996 - val_loss: 0.5401 - val_accuracy: 0.8074\n",
            "Epoch 167/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2741 - accuracy: 0.9052 - val_loss: 0.5183 - val_accuracy: 0.8296\n",
            "Epoch 168/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2761 - accuracy: 0.8959 - val_loss: 0.5380 - val_accuracy: 0.8000\n",
            "Epoch 169/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2715 - accuracy: 0.8978 - val_loss: 0.5408 - val_accuracy: 0.8000\n",
            "Epoch 170/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2697 - accuracy: 0.8996 - val_loss: 0.5446 - val_accuracy: 0.7926\n",
            "Epoch 171/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2664 - accuracy: 0.9015 - val_loss: 0.5304 - val_accuracy: 0.8000\n",
            "Epoch 172/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2686 - accuracy: 0.8959 - val_loss: 0.5335 - val_accuracy: 0.8222\n",
            "Epoch 173/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2672 - accuracy: 0.8922 - val_loss: 0.5550 - val_accuracy: 0.8074\n",
            "Epoch 174/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2643 - accuracy: 0.9071 - val_loss: 0.5353 - val_accuracy: 0.8000\n",
            "Epoch 175/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2654 - accuracy: 0.8903 - val_loss: 0.5516 - val_accuracy: 0.8000\n",
            "Epoch 176/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2653 - accuracy: 0.9052 - val_loss: 0.5551 - val_accuracy: 0.8074\n",
            "Epoch 177/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2649 - accuracy: 0.9015 - val_loss: 0.5423 - val_accuracy: 0.8148\n",
            "Epoch 178/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2614 - accuracy: 0.9071 - val_loss: 0.5356 - val_accuracy: 0.8222\n",
            "Epoch 179/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2617 - accuracy: 0.9015 - val_loss: 0.5580 - val_accuracy: 0.8148\n",
            "Epoch 180/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2620 - accuracy: 0.9033 - val_loss: 0.5615 - val_accuracy: 0.8074\n",
            "Epoch 181/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2574 - accuracy: 0.9052 - val_loss: 0.5389 - val_accuracy: 0.8000\n",
            "Epoch 182/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2597 - accuracy: 0.8848 - val_loss: 0.5687 - val_accuracy: 0.7926\n",
            "Epoch 183/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2627 - accuracy: 0.8996 - val_loss: 0.5328 - val_accuracy: 0.8296\n",
            "Epoch 184/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2586 - accuracy: 0.8922 - val_loss: 0.5828 - val_accuracy: 0.7926\n",
            "Epoch 185/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2551 - accuracy: 0.9033 - val_loss: 0.5379 - val_accuracy: 0.8148\n",
            "Epoch 186/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2505 - accuracy: 0.8996 - val_loss: 0.5573 - val_accuracy: 0.7926\n",
            "Epoch 187/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.2481 - accuracy: 0.9071 - val_loss: 0.5476 - val_accuracy: 0.8074\n",
            "Epoch 188/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2480 - accuracy: 0.8959 - val_loss: 0.5481 - val_accuracy: 0.8222\n",
            "Epoch 189/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2465 - accuracy: 0.9071 - val_loss: 0.5513 - val_accuracy: 0.8074\n",
            "Epoch 190/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2478 - accuracy: 0.9015 - val_loss: 0.5469 - val_accuracy: 0.8074\n",
            "Epoch 191/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2456 - accuracy: 0.9033 - val_loss: 0.5695 - val_accuracy: 0.8000\n",
            "Epoch 192/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2453 - accuracy: 0.8996 - val_loss: 0.5583 - val_accuracy: 0.8074\n",
            "Epoch 193/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2430 - accuracy: 0.9126 - val_loss: 0.5415 - val_accuracy: 0.8222\n",
            "Epoch 194/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2480 - accuracy: 0.9052 - val_loss: 0.5642 - val_accuracy: 0.8074\n",
            "Epoch 195/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2429 - accuracy: 0.9052 - val_loss: 0.5672 - val_accuracy: 0.8074\n",
            "Epoch 196/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2397 - accuracy: 0.9089 - val_loss: 0.5479 - val_accuracy: 0.8222\n",
            "Epoch 197/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2408 - accuracy: 0.9052 - val_loss: 0.5789 - val_accuracy: 0.8000\n",
            "Epoch 198/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2380 - accuracy: 0.9052 - val_loss: 0.5588 - val_accuracy: 0.8148\n",
            "Epoch 199/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2367 - accuracy: 0.9145 - val_loss: 0.5640 - val_accuracy: 0.8074\n",
            "Epoch 200/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2358 - accuracy: 0.9033 - val_loss: 0.5711 - val_accuracy: 0.8074\n",
            "Epoch 201/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2346 - accuracy: 0.9126 - val_loss: 0.5733 - val_accuracy: 0.8074\n",
            "Epoch 202/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2329 - accuracy: 0.9089 - val_loss: 0.5551 - val_accuracy: 0.8074\n",
            "Epoch 203/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2346 - accuracy: 0.9089 - val_loss: 0.5684 - val_accuracy: 0.8148\n",
            "Epoch 204/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2344 - accuracy: 0.8959 - val_loss: 0.5642 - val_accuracy: 0.8074\n",
            "Epoch 205/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2353 - accuracy: 0.9052 - val_loss: 0.5398 - val_accuracy: 0.8444\n",
            "Epoch 206/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.2409 - accuracy: 0.8996 - val_loss: 0.5978 - val_accuracy: 0.8000\n",
            "Epoch 207/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.2255 - accuracy: 0.9145 - val_loss: 0.5576 - val_accuracy: 0.8222\n",
            "Epoch 208/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.2326 - accuracy: 0.9033 - val_loss: 0.5955 - val_accuracy: 0.7926\n",
            "Epoch 209/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.2318 - accuracy: 0.9145 - val_loss: 0.5690 - val_accuracy: 0.8222\n",
            "Epoch 210/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2268 - accuracy: 0.9108 - val_loss: 0.5836 - val_accuracy: 0.8074\n",
            "Epoch 211/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2288 - accuracy: 0.9126 - val_loss: 0.5411 - val_accuracy: 0.8519\n",
            "Epoch 212/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2257 - accuracy: 0.9089 - val_loss: 0.6234 - val_accuracy: 0.7926\n",
            "Epoch 213/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2263 - accuracy: 0.9164 - val_loss: 0.5637 - val_accuracy: 0.8074\n",
            "Epoch 214/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.2249 - accuracy: 0.9108 - val_loss: 0.5811 - val_accuracy: 0.8148\n",
            "Epoch 215/500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.2219 - accuracy: 0.9033 - val_loss: 0.5863 - val_accuracy: 0.8074\n",
            "Epoch 216/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2196 - accuracy: 0.9201 - val_loss: 0.5739 - val_accuracy: 0.8222\n",
            "Epoch 217/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.2199 - accuracy: 0.9126 - val_loss: 0.5690 - val_accuracy: 0.8222\n",
            "Epoch 218/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2179 - accuracy: 0.9164 - val_loss: 0.5682 - val_accuracy: 0.8222\n",
            "Epoch 219/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2193 - accuracy: 0.9164 - val_loss: 0.5986 - val_accuracy: 0.8074\n",
            "Epoch 220/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.2177 - accuracy: 0.9164 - val_loss: 0.5814 - val_accuracy: 0.8370\n",
            "Epoch 221/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.2179 - accuracy: 0.9126 - val_loss: 0.5686 - val_accuracy: 0.8222\n",
            "Epoch 222/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2216 - accuracy: 0.9164 - val_loss: 0.5691 - val_accuracy: 0.8296\n",
            "Epoch 223/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.2172 - accuracy: 0.9089 - val_loss: 0.5996 - val_accuracy: 0.8074\n",
            "Epoch 224/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2145 - accuracy: 0.9219 - val_loss: 0.5903 - val_accuracy: 0.8148\n",
            "Epoch 225/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2138 - accuracy: 0.9201 - val_loss: 0.5714 - val_accuracy: 0.8370\n",
            "Epoch 226/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.2174 - accuracy: 0.9145 - val_loss: 0.5843 - val_accuracy: 0.8222\n",
            "Epoch 227/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2112 - accuracy: 0.9238 - val_loss: 0.5822 - val_accuracy: 0.8148\n",
            "Epoch 228/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2101 - accuracy: 0.9164 - val_loss: 0.5990 - val_accuracy: 0.8222\n",
            "Epoch 229/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2090 - accuracy: 0.9145 - val_loss: 0.5903 - val_accuracy: 0.8148\n",
            "Epoch 230/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2096 - accuracy: 0.9182 - val_loss: 0.5891 - val_accuracy: 0.8148\n",
            "Epoch 231/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2065 - accuracy: 0.9164 - val_loss: 0.5940 - val_accuracy: 0.8296\n",
            "Epoch 232/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2075 - accuracy: 0.9145 - val_loss: 0.6074 - val_accuracy: 0.8074\n",
            "Epoch 233/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2077 - accuracy: 0.9238 - val_loss: 0.5974 - val_accuracy: 0.8296\n",
            "Epoch 234/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2034 - accuracy: 0.9201 - val_loss: 0.6151 - val_accuracy: 0.7926\n",
            "Epoch 235/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2030 - accuracy: 0.9219 - val_loss: 0.5839 - val_accuracy: 0.8222\n",
            "Epoch 236/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2018 - accuracy: 0.9238 - val_loss: 0.5970 - val_accuracy: 0.8222\n",
            "Epoch 237/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1996 - accuracy: 0.9219 - val_loss: 0.5956 - val_accuracy: 0.8296\n",
            "Epoch 238/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2022 - accuracy: 0.9275 - val_loss: 0.5747 - val_accuracy: 0.8370\n",
            "Epoch 239/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2017 - accuracy: 0.9164 - val_loss: 0.6105 - val_accuracy: 0.8148\n",
            "Epoch 240/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.1988 - accuracy: 0.9275 - val_loss: 0.5853 - val_accuracy: 0.8148\n",
            "Epoch 241/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.1992 - accuracy: 0.9201 - val_loss: 0.5938 - val_accuracy: 0.8296\n",
            "Epoch 242/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1989 - accuracy: 0.9275 - val_loss: 0.6049 - val_accuracy: 0.8296\n",
            "Epoch 243/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1994 - accuracy: 0.9182 - val_loss: 0.5848 - val_accuracy: 0.8222\n",
            "Epoch 244/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1972 - accuracy: 0.9275 - val_loss: 0.6103 - val_accuracy: 0.8296\n",
            "Epoch 245/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2002 - accuracy: 0.9201 - val_loss: 0.5884 - val_accuracy: 0.8296\n",
            "Epoch 246/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1999 - accuracy: 0.9201 - val_loss: 0.6063 - val_accuracy: 0.8148\n",
            "Epoch 247/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1991 - accuracy: 0.9201 - val_loss: 0.5978 - val_accuracy: 0.8222\n",
            "Epoch 248/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1909 - accuracy: 0.9331 - val_loss: 0.5913 - val_accuracy: 0.8370\n",
            "Epoch 249/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1909 - accuracy: 0.9257 - val_loss: 0.6225 - val_accuracy: 0.8000\n",
            "Epoch 250/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1931 - accuracy: 0.9257 - val_loss: 0.6072 - val_accuracy: 0.8074\n",
            "Epoch 251/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1903 - accuracy: 0.9257 - val_loss: 0.6140 - val_accuracy: 0.8370\n",
            "Epoch 252/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1921 - accuracy: 0.9405 - val_loss: 0.5985 - val_accuracy: 0.8370\n",
            "Epoch 253/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1921 - accuracy: 0.9387 - val_loss: 0.6060 - val_accuracy: 0.8222\n",
            "Epoch 254/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1930 - accuracy: 0.9182 - val_loss: 0.6218 - val_accuracy: 0.8222\n",
            "Epoch 255/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1912 - accuracy: 0.9294 - val_loss: 0.6059 - val_accuracy: 0.8148\n",
            "Epoch 256/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1901 - accuracy: 0.9238 - val_loss: 0.6254 - val_accuracy: 0.8148\n",
            "Epoch 257/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1862 - accuracy: 0.9312 - val_loss: 0.5929 - val_accuracy: 0.8222\n",
            "Epoch 258/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1842 - accuracy: 0.9257 - val_loss: 0.6284 - val_accuracy: 0.8222\n",
            "Epoch 259/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1856 - accuracy: 0.9349 - val_loss: 0.6254 - val_accuracy: 0.7926\n",
            "Epoch 260/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1857 - accuracy: 0.9312 - val_loss: 0.6206 - val_accuracy: 0.8296\n",
            "Epoch 261/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1854 - accuracy: 0.9238 - val_loss: 0.5947 - val_accuracy: 0.8296\n",
            "Epoch 262/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1812 - accuracy: 0.9294 - val_loss: 0.6126 - val_accuracy: 0.8444\n",
            "Epoch 263/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1817 - accuracy: 0.9368 - val_loss: 0.6061 - val_accuracy: 0.8296\n",
            "Epoch 264/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1858 - accuracy: 0.9349 - val_loss: 0.6296 - val_accuracy: 0.8296\n",
            "Epoch 265/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1790 - accuracy: 0.9424 - val_loss: 0.6140 - val_accuracy: 0.8296\n",
            "Epoch 266/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1826 - accuracy: 0.9312 - val_loss: 0.6645 - val_accuracy: 0.8000\n",
            "Epoch 267/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1816 - accuracy: 0.9257 - val_loss: 0.6028 - val_accuracy: 0.8222\n",
            "Epoch 268/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1797 - accuracy: 0.9349 - val_loss: 0.6133 - val_accuracy: 0.8296\n",
            "Epoch 269/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1761 - accuracy: 0.9331 - val_loss: 0.6239 - val_accuracy: 0.8000\n",
            "Epoch 270/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1779 - accuracy: 0.9387 - val_loss: 0.6124 - val_accuracy: 0.8148\n",
            "Epoch 271/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1761 - accuracy: 0.9312 - val_loss: 0.6262 - val_accuracy: 0.8074\n",
            "Epoch 272/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1732 - accuracy: 0.9442 - val_loss: 0.6239 - val_accuracy: 0.8296\n",
            "Epoch 273/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1739 - accuracy: 0.9312 - val_loss: 0.6273 - val_accuracy: 0.8222\n",
            "Epoch 274/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1733 - accuracy: 0.9349 - val_loss: 0.6359 - val_accuracy: 0.8074\n",
            "Epoch 275/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1712 - accuracy: 0.9424 - val_loss: 0.6300 - val_accuracy: 0.8222\n",
            "Epoch 276/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.1730 - accuracy: 0.9368 - val_loss: 0.6287 - val_accuracy: 0.8222\n",
            "Epoch 277/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1724 - accuracy: 0.9424 - val_loss: 0.6266 - val_accuracy: 0.8222\n",
            "Epoch 278/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1689 - accuracy: 0.9442 - val_loss: 0.6327 - val_accuracy: 0.8000\n",
            "Epoch 279/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1704 - accuracy: 0.9257 - val_loss: 0.6435 - val_accuracy: 0.8074\n",
            "Epoch 280/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1664 - accuracy: 0.9442 - val_loss: 0.6103 - val_accuracy: 0.8370\n",
            "Epoch 281/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1677 - accuracy: 0.9368 - val_loss: 0.6339 - val_accuracy: 0.8296\n",
            "Epoch 282/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1655 - accuracy: 0.9461 - val_loss: 0.6424 - val_accuracy: 0.8074\n",
            "Epoch 283/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1701 - accuracy: 0.9405 - val_loss: 0.6399 - val_accuracy: 0.8222\n",
            "Epoch 284/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1648 - accuracy: 0.9461 - val_loss: 0.6399 - val_accuracy: 0.8148\n",
            "Epoch 285/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1666 - accuracy: 0.9424 - val_loss: 0.6557 - val_accuracy: 0.8000\n",
            "Epoch 286/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1630 - accuracy: 0.9387 - val_loss: 0.6369 - val_accuracy: 0.8296\n",
            "Epoch 287/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1645 - accuracy: 0.9405 - val_loss: 0.6430 - val_accuracy: 0.8000\n",
            "Epoch 288/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1627 - accuracy: 0.9368 - val_loss: 0.6525 - val_accuracy: 0.8000\n",
            "Epoch 289/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1657 - accuracy: 0.9498 - val_loss: 0.6438 - val_accuracy: 0.8296\n",
            "Epoch 290/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1673 - accuracy: 0.9405 - val_loss: 0.6572 - val_accuracy: 0.7852\n",
            "Epoch 291/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1658 - accuracy: 0.9405 - val_loss: 0.6424 - val_accuracy: 0.8148\n",
            "Epoch 292/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1629 - accuracy: 0.9424 - val_loss: 0.6707 - val_accuracy: 0.7926\n",
            "Epoch 293/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1615 - accuracy: 0.9349 - val_loss: 0.6737 - val_accuracy: 0.7926\n",
            "Epoch 294/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1640 - accuracy: 0.9424 - val_loss: 0.6413 - val_accuracy: 0.8074\n",
            "Epoch 295/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1593 - accuracy: 0.9480 - val_loss: 0.6271 - val_accuracy: 0.8148\n",
            "Epoch 296/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1591 - accuracy: 0.9424 - val_loss: 0.6543 - val_accuracy: 0.8148\n",
            "Epoch 297/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1610 - accuracy: 0.9349 - val_loss: 0.6547 - val_accuracy: 0.7926\n",
            "Epoch 298/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1578 - accuracy: 0.9442 - val_loss: 0.6769 - val_accuracy: 0.8000\n",
            "Epoch 299/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1579 - accuracy: 0.9405 - val_loss: 0.6540 - val_accuracy: 0.8148\n",
            "Epoch 300/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1546 - accuracy: 0.9480 - val_loss: 0.6538 - val_accuracy: 0.8296\n",
            "Epoch 301/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1544 - accuracy: 0.9387 - val_loss: 0.6574 - val_accuracy: 0.8222\n",
            "Epoch 302/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1543 - accuracy: 0.9442 - val_loss: 0.6506 - val_accuracy: 0.8000\n",
            "Epoch 303/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1554 - accuracy: 0.9535 - val_loss: 0.6614 - val_accuracy: 0.8222\n",
            "Epoch 304/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1534 - accuracy: 0.9461 - val_loss: 0.6769 - val_accuracy: 0.7926\n",
            "Epoch 305/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1585 - accuracy: 0.9442 - val_loss: 0.6391 - val_accuracy: 0.8222\n",
            "Epoch 306/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1552 - accuracy: 0.9442 - val_loss: 0.6378 - val_accuracy: 0.8074\n",
            "Epoch 307/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.1547 - accuracy: 0.9405 - val_loss: 0.6871 - val_accuracy: 0.7778\n",
            "Epoch 308/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1481 - accuracy: 0.9517 - val_loss: 0.6337 - val_accuracy: 0.8222\n",
            "Epoch 309/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1500 - accuracy: 0.9480 - val_loss: 0.6758 - val_accuracy: 0.7926\n",
            "Epoch 310/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1504 - accuracy: 0.9535 - val_loss: 0.6807 - val_accuracy: 0.8074\n",
            "Epoch 311/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1535 - accuracy: 0.9535 - val_loss: 0.6775 - val_accuracy: 0.8074\n",
            "Epoch 312/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.1484 - accuracy: 0.9480 - val_loss: 0.6465 - val_accuracy: 0.8370\n",
            "Epoch 313/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.1456 - accuracy: 0.9480 - val_loss: 0.6719 - val_accuracy: 0.8000\n",
            "Epoch 314/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.1475 - accuracy: 0.9461 - val_loss: 0.6606 - val_accuracy: 0.8222\n",
            "Epoch 315/500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.1433 - accuracy: 0.9498 - val_loss: 0.6766 - val_accuracy: 0.8074\n",
            "Epoch 316/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.1461 - accuracy: 0.9424 - val_loss: 0.6571 - val_accuracy: 0.8074\n",
            "Epoch 317/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1431 - accuracy: 0.9517 - val_loss: 0.6625 - val_accuracy: 0.8222\n",
            "Epoch 318/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1458 - accuracy: 0.9405 - val_loss: 0.6618 - val_accuracy: 0.8148\n",
            "Epoch 319/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.1436 - accuracy: 0.9461 - val_loss: 0.6562 - val_accuracy: 0.8074\n",
            "Epoch 320/500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.1433 - accuracy: 0.9498 - val_loss: 0.6653 - val_accuracy: 0.8222\n",
            "Epoch 321/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1392 - accuracy: 0.9535 - val_loss: 0.6808 - val_accuracy: 0.8000\n",
            "Epoch 322/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1400 - accuracy: 0.9480 - val_loss: 0.6615 - val_accuracy: 0.8296\n",
            "Epoch 323/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1395 - accuracy: 0.9480 - val_loss: 0.6920 - val_accuracy: 0.7852\n",
            "Epoch 324/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1438 - accuracy: 0.9480 - val_loss: 0.6896 - val_accuracy: 0.7926\n",
            "Epoch 325/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1415 - accuracy: 0.9535 - val_loss: 0.6715 - val_accuracy: 0.8074\n",
            "Epoch 326/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.1390 - accuracy: 0.9480 - val_loss: 0.6807 - val_accuracy: 0.8074\n",
            "Epoch 327/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.1402 - accuracy: 0.9535 - val_loss: 0.6587 - val_accuracy: 0.8296\n",
            "Epoch 328/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.1363 - accuracy: 0.9517 - val_loss: 0.6979 - val_accuracy: 0.8000\n",
            "Epoch 329/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.1359 - accuracy: 0.9572 - val_loss: 0.6604 - val_accuracy: 0.8222\n",
            "Epoch 330/500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.1366 - accuracy: 0.9554 - val_loss: 0.6806 - val_accuracy: 0.8296\n",
            "Epoch 331/500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.1334 - accuracy: 0.9610 - val_loss: 0.6736 - val_accuracy: 0.8074\n",
            "Epoch 332/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.1367 - accuracy: 0.9572 - val_loss: 0.7061 - val_accuracy: 0.8000\n",
            "Epoch 333/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1363 - accuracy: 0.9498 - val_loss: 0.7086 - val_accuracy: 0.8000\n",
            "Epoch 334/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1361 - accuracy: 0.9591 - val_loss: 0.6597 - val_accuracy: 0.8370\n",
            "Epoch 335/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1338 - accuracy: 0.9535 - val_loss: 0.6948 - val_accuracy: 0.8074\n",
            "Epoch 336/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1328 - accuracy: 0.9535 - val_loss: 0.6916 - val_accuracy: 0.8074\n",
            "Epoch 337/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1315 - accuracy: 0.9535 - val_loss: 0.6928 - val_accuracy: 0.8000\n",
            "Epoch 338/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1344 - accuracy: 0.9517 - val_loss: 0.6809 - val_accuracy: 0.8074\n",
            "Epoch 339/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1323 - accuracy: 0.9535 - val_loss: 0.6851 - val_accuracy: 0.8222\n",
            "Epoch 340/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1331 - accuracy: 0.9535 - val_loss: 0.6850 - val_accuracy: 0.8000\n",
            "Epoch 341/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1306 - accuracy: 0.9517 - val_loss: 0.6783 - val_accuracy: 0.8074\n",
            "Epoch 342/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1326 - accuracy: 0.9517 - val_loss: 0.7050 - val_accuracy: 0.8000\n",
            "Epoch 343/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1286 - accuracy: 0.9554 - val_loss: 0.6823 - val_accuracy: 0.8222\n",
            "Epoch 344/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1287 - accuracy: 0.9554 - val_loss: 0.6916 - val_accuracy: 0.8296\n",
            "Epoch 345/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1288 - accuracy: 0.9572 - val_loss: 0.6916 - val_accuracy: 0.8296\n",
            "Epoch 346/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1272 - accuracy: 0.9628 - val_loss: 0.7089 - val_accuracy: 0.8074\n",
            "Epoch 347/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1248 - accuracy: 0.9554 - val_loss: 0.7022 - val_accuracy: 0.8074\n",
            "Epoch 348/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1253 - accuracy: 0.9610 - val_loss: 0.6916 - val_accuracy: 0.8222\n",
            "Epoch 349/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1250 - accuracy: 0.9535 - val_loss: 0.7060 - val_accuracy: 0.7926\n",
            "Epoch 350/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1317 - accuracy: 0.9442 - val_loss: 0.6944 - val_accuracy: 0.8370\n",
            "Epoch 351/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1256 - accuracy: 0.9554 - val_loss: 0.7137 - val_accuracy: 0.7926\n",
            "Epoch 352/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1242 - accuracy: 0.9535 - val_loss: 0.6802 - val_accuracy: 0.8222\n",
            "Epoch 353/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1241 - accuracy: 0.9572 - val_loss: 0.7040 - val_accuracy: 0.8370\n",
            "Epoch 354/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1230 - accuracy: 0.9610 - val_loss: 0.7010 - val_accuracy: 0.8148\n",
            "Epoch 355/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1229 - accuracy: 0.9535 - val_loss: 0.7108 - val_accuracy: 0.8000\n",
            "Epoch 356/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1216 - accuracy: 0.9591 - val_loss: 0.7189 - val_accuracy: 0.8074\n",
            "Epoch 357/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1220 - accuracy: 0.9610 - val_loss: 0.6959 - val_accuracy: 0.8222\n",
            "Epoch 358/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1217 - accuracy: 0.9628 - val_loss: 0.7238 - val_accuracy: 0.8074\n",
            "Epoch 359/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1188 - accuracy: 0.9610 - val_loss: 0.7099 - val_accuracy: 0.8074\n",
            "Epoch 360/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1232 - accuracy: 0.9535 - val_loss: 0.7382 - val_accuracy: 0.7852\n",
            "Epoch 361/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1257 - accuracy: 0.9610 - val_loss: 0.6936 - val_accuracy: 0.8148\n",
            "Epoch 362/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1214 - accuracy: 0.9572 - val_loss: 0.7517 - val_accuracy: 0.7630\n",
            "Epoch 363/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1201 - accuracy: 0.9572 - val_loss: 0.7042 - val_accuracy: 0.8148\n",
            "Epoch 364/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1195 - accuracy: 0.9591 - val_loss: 0.6965 - val_accuracy: 0.8222\n",
            "Epoch 365/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1180 - accuracy: 0.9572 - val_loss: 0.7281 - val_accuracy: 0.8222\n",
            "Epoch 366/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1174 - accuracy: 0.9610 - val_loss: 0.6841 - val_accuracy: 0.8296\n",
            "Epoch 367/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1165 - accuracy: 0.9628 - val_loss: 0.7191 - val_accuracy: 0.8148\n",
            "Epoch 368/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1154 - accuracy: 0.9684 - val_loss: 0.7237 - val_accuracy: 0.8148\n",
            "Epoch 369/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1164 - accuracy: 0.9610 - val_loss: 0.7183 - val_accuracy: 0.8222\n",
            "Epoch 370/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1146 - accuracy: 0.9591 - val_loss: 0.7304 - val_accuracy: 0.7852\n",
            "Epoch 371/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1137 - accuracy: 0.9628 - val_loss: 0.7018 - val_accuracy: 0.8296\n",
            "Epoch 372/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1124 - accuracy: 0.9628 - val_loss: 0.7306 - val_accuracy: 0.8148\n",
            "Epoch 373/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1128 - accuracy: 0.9647 - val_loss: 0.7054 - val_accuracy: 0.8222\n",
            "Epoch 374/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1118 - accuracy: 0.9647 - val_loss: 0.7314 - val_accuracy: 0.8074\n",
            "Epoch 375/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1132 - accuracy: 0.9610 - val_loss: 0.7076 - val_accuracy: 0.8222\n",
            "Epoch 376/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1117 - accuracy: 0.9647 - val_loss: 0.7701 - val_accuracy: 0.7704\n",
            "Epoch 377/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1143 - accuracy: 0.9610 - val_loss: 0.7022 - val_accuracy: 0.8370\n",
            "Epoch 378/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1103 - accuracy: 0.9628 - val_loss: 0.7317 - val_accuracy: 0.8074\n",
            "Epoch 379/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1089 - accuracy: 0.9665 - val_loss: 0.7394 - val_accuracy: 0.8000\n",
            "Epoch 380/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1096 - accuracy: 0.9647 - val_loss: 0.7391 - val_accuracy: 0.8000\n",
            "Epoch 381/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1086 - accuracy: 0.9628 - val_loss: 0.7356 - val_accuracy: 0.7926\n",
            "Epoch 382/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1093 - accuracy: 0.9684 - val_loss: 0.7013 - val_accuracy: 0.8222\n",
            "Epoch 383/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1093 - accuracy: 0.9665 - val_loss: 0.7504 - val_accuracy: 0.7778\n",
            "Epoch 384/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1093 - accuracy: 0.9628 - val_loss: 0.7107 - val_accuracy: 0.8074\n",
            "Epoch 385/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1067 - accuracy: 0.9591 - val_loss: 0.7243 - val_accuracy: 0.8074\n",
            "Epoch 386/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1070 - accuracy: 0.9665 - val_loss: 0.7496 - val_accuracy: 0.8000\n",
            "Epoch 387/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1058 - accuracy: 0.9647 - val_loss: 0.7256 - val_accuracy: 0.8148\n",
            "Epoch 388/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.9665 - val_loss: 0.7222 - val_accuracy: 0.8222\n",
            "Epoch 389/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1092 - accuracy: 0.9703 - val_loss: 0.7088 - val_accuracy: 0.8148\n",
            "Epoch 390/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1104 - accuracy: 0.9628 - val_loss: 0.7674 - val_accuracy: 0.7556\n",
            "Epoch 391/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1070 - accuracy: 0.9647 - val_loss: 0.7134 - val_accuracy: 0.8296\n",
            "Epoch 392/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1049 - accuracy: 0.9628 - val_loss: 0.7502 - val_accuracy: 0.7852\n",
            "Epoch 393/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1044 - accuracy: 0.9740 - val_loss: 0.7352 - val_accuracy: 0.8074\n",
            "Epoch 394/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1044 - accuracy: 0.9684 - val_loss: 0.7231 - val_accuracy: 0.8148\n",
            "Epoch 395/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1056 - accuracy: 0.9610 - val_loss: 0.7198 - val_accuracy: 0.8296\n",
            "Epoch 396/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1016 - accuracy: 0.9684 - val_loss: 0.7614 - val_accuracy: 0.7852\n",
            "Epoch 397/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1077 - accuracy: 0.9572 - val_loss: 0.7416 - val_accuracy: 0.8074\n",
            "Epoch 398/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1037 - accuracy: 0.9740 - val_loss: 0.7124 - val_accuracy: 0.8222\n",
            "Epoch 399/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0995 - accuracy: 0.9684 - val_loss: 0.7471 - val_accuracy: 0.8074\n",
            "Epoch 400/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1004 - accuracy: 0.9684 - val_loss: 0.7171 - val_accuracy: 0.8074\n",
            "Epoch 401/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0990 - accuracy: 0.9684 - val_loss: 0.7601 - val_accuracy: 0.8074\n",
            "Epoch 402/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1017 - accuracy: 0.9628 - val_loss: 0.7052 - val_accuracy: 0.8296\n",
            "Epoch 403/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1016 - accuracy: 0.9665 - val_loss: 0.7808 - val_accuracy: 0.7852\n",
            "Epoch 404/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0970 - accuracy: 0.9721 - val_loss: 0.7186 - val_accuracy: 0.8074\n",
            "Epoch 405/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0975 - accuracy: 0.9721 - val_loss: 0.7331 - val_accuracy: 0.8000\n",
            "Epoch 406/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0998 - accuracy: 0.9721 - val_loss: 0.7368 - val_accuracy: 0.8000\n",
            "Epoch 407/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0995 - accuracy: 0.9684 - val_loss: 0.7406 - val_accuracy: 0.8074\n",
            "Epoch 408/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0982 - accuracy: 0.9740 - val_loss: 0.7517 - val_accuracy: 0.7926\n",
            "Epoch 409/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0983 - accuracy: 0.9684 - val_loss: 0.7400 - val_accuracy: 0.8148\n",
            "Epoch 410/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0955 - accuracy: 0.9740 - val_loss: 0.7470 - val_accuracy: 0.8074\n",
            "Epoch 411/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0979 - accuracy: 0.9665 - val_loss: 0.7872 - val_accuracy: 0.7704\n",
            "Epoch 412/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0966 - accuracy: 0.9703 - val_loss: 0.7332 - val_accuracy: 0.8148\n",
            "Epoch 413/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0971 - accuracy: 0.9721 - val_loss: 0.7578 - val_accuracy: 0.7926\n",
            "Epoch 414/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0929 - accuracy: 0.9721 - val_loss: 0.7396 - val_accuracy: 0.8222\n",
            "Epoch 415/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0969 - accuracy: 0.9647 - val_loss: 0.7599 - val_accuracy: 0.8000\n",
            "Epoch 416/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.0932 - accuracy: 0.9740 - val_loss: 0.7402 - val_accuracy: 0.8000\n",
            "Epoch 417/500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0931 - accuracy: 0.9721 - val_loss: 0.7591 - val_accuracy: 0.8074\n",
            "Epoch 418/500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0927 - accuracy: 0.9777 - val_loss: 0.7358 - val_accuracy: 0.8000\n",
            "Epoch 419/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.0953 - accuracy: 0.9647 - val_loss: 0.7601 - val_accuracy: 0.8000\n",
            "Epoch 420/500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0946 - accuracy: 0.9721 - val_loss: 0.7531 - val_accuracy: 0.8222\n",
            "Epoch 421/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0909 - accuracy: 0.9740 - val_loss: 0.7583 - val_accuracy: 0.7926\n",
            "Epoch 422/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0899 - accuracy: 0.9758 - val_loss: 0.7603 - val_accuracy: 0.8074\n",
            "Epoch 423/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0918 - accuracy: 0.9740 - val_loss: 0.7503 - val_accuracy: 0.8000\n",
            "Epoch 424/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.0931 - accuracy: 0.9740 - val_loss: 0.7818 - val_accuracy: 0.7704\n",
            "Epoch 425/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0901 - accuracy: 0.9703 - val_loss: 0.7497 - val_accuracy: 0.8074\n",
            "Epoch 426/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0917 - accuracy: 0.9740 - val_loss: 0.7779 - val_accuracy: 0.8000\n",
            "Epoch 427/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.0881 - accuracy: 0.9721 - val_loss: 0.7556 - val_accuracy: 0.8000\n",
            "Epoch 428/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0877 - accuracy: 0.9777 - val_loss: 0.7761 - val_accuracy: 0.7852\n",
            "Epoch 429/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.0881 - accuracy: 0.9796 - val_loss: 0.7382 - val_accuracy: 0.8074\n",
            "Epoch 430/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0953 - accuracy: 0.9721 - val_loss: 0.7621 - val_accuracy: 0.8074\n",
            "Epoch 431/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0952 - accuracy: 0.9665 - val_loss: 0.8160 - val_accuracy: 0.7630\n",
            "Epoch 432/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0905 - accuracy: 0.9721 - val_loss: 0.7364 - val_accuracy: 0.8000\n",
            "Epoch 433/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0867 - accuracy: 0.9758 - val_loss: 0.7847 - val_accuracy: 0.7852\n",
            "Epoch 434/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.0862 - accuracy: 0.9758 - val_loss: 0.7604 - val_accuracy: 0.8074\n",
            "Epoch 435/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0878 - accuracy: 0.9758 - val_loss: 0.7673 - val_accuracy: 0.8000\n",
            "Epoch 436/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0846 - accuracy: 0.9758 - val_loss: 0.7577 - val_accuracy: 0.8074\n",
            "Epoch 437/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0845 - accuracy: 0.9777 - val_loss: 0.7674 - val_accuracy: 0.7926\n",
            "Epoch 438/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.0855 - accuracy: 0.9777 - val_loss: 0.7601 - val_accuracy: 0.7926\n",
            "Epoch 439/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.0841 - accuracy: 0.9777 - val_loss: 0.7639 - val_accuracy: 0.8000\n",
            "Epoch 440/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0848 - accuracy: 0.9758 - val_loss: 0.7534 - val_accuracy: 0.8000\n",
            "Epoch 441/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0869 - accuracy: 0.9740 - val_loss: 0.7740 - val_accuracy: 0.7926\n",
            "Epoch 442/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0840 - accuracy: 0.9758 - val_loss: 0.7708 - val_accuracy: 0.8074\n",
            "Epoch 443/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.0829 - accuracy: 0.9777 - val_loss: 0.7589 - val_accuracy: 0.7778\n",
            "Epoch 444/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0846 - accuracy: 0.9796 - val_loss: 0.8208 - val_accuracy: 0.7852\n",
            "Epoch 445/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0861 - accuracy: 0.9703 - val_loss: 0.7568 - val_accuracy: 0.8148\n",
            "Epoch 446/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0858 - accuracy: 0.9721 - val_loss: 0.7594 - val_accuracy: 0.7926\n",
            "Epoch 447/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0817 - accuracy: 0.9796 - val_loss: 0.7760 - val_accuracy: 0.8074\n",
            "Epoch 448/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0825 - accuracy: 0.9777 - val_loss: 0.7978 - val_accuracy: 0.7778\n",
            "Epoch 449/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0825 - accuracy: 0.9777 - val_loss: 0.7673 - val_accuracy: 0.8074\n",
            "Epoch 450/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0800 - accuracy: 0.9796 - val_loss: 0.7601 - val_accuracy: 0.8074\n",
            "Epoch 451/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0812 - accuracy: 0.9796 - val_loss: 0.7503 - val_accuracy: 0.8074\n",
            "Epoch 452/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0838 - accuracy: 0.9684 - val_loss: 0.8375 - val_accuracy: 0.7630\n",
            "Epoch 453/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0830 - accuracy: 0.9758 - val_loss: 0.7754 - val_accuracy: 0.7926\n",
            "Epoch 454/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0795 - accuracy: 0.9796 - val_loss: 0.7840 - val_accuracy: 0.8000\n",
            "Epoch 455/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0798 - accuracy: 0.9758 - val_loss: 0.7650 - val_accuracy: 0.7926\n",
            "Epoch 456/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0792 - accuracy: 0.9777 - val_loss: 0.7736 - val_accuracy: 0.7926\n",
            "Epoch 457/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0785 - accuracy: 0.9796 - val_loss: 0.8080 - val_accuracy: 0.7778\n",
            "Epoch 458/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0782 - accuracy: 0.9814 - val_loss: 0.7677 - val_accuracy: 0.7852\n",
            "Epoch 459/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0775 - accuracy: 0.9777 - val_loss: 0.7755 - val_accuracy: 0.7852\n",
            "Epoch 460/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0782 - accuracy: 0.9777 - val_loss: 0.7893 - val_accuracy: 0.7778\n",
            "Epoch 461/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0804 - accuracy: 0.9796 - val_loss: 0.7911 - val_accuracy: 0.8000\n",
            "Epoch 462/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0798 - accuracy: 0.9814 - val_loss: 0.7568 - val_accuracy: 0.8148\n",
            "Epoch 463/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0796 - accuracy: 0.9814 - val_loss: 0.7936 - val_accuracy: 0.7926\n",
            "Epoch 464/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0787 - accuracy: 0.9796 - val_loss: 0.7790 - val_accuracy: 0.7852\n",
            "Epoch 465/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0761 - accuracy: 0.9833 - val_loss: 0.7933 - val_accuracy: 0.7704\n",
            "Epoch 466/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0772 - accuracy: 0.9796 - val_loss: 0.7793 - val_accuracy: 0.7926\n",
            "Epoch 467/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0790 - accuracy: 0.9758 - val_loss: 0.7876 - val_accuracy: 0.8000\n",
            "Epoch 468/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0746 - accuracy: 0.9796 - val_loss: 0.7834 - val_accuracy: 0.7852\n",
            "Epoch 469/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0760 - accuracy: 0.9777 - val_loss: 0.8016 - val_accuracy: 0.7852\n",
            "Epoch 470/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0739 - accuracy: 0.9796 - val_loss: 0.7710 - val_accuracy: 0.8148\n",
            "Epoch 471/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0746 - accuracy: 0.9796 - val_loss: 0.7909 - val_accuracy: 0.7852\n",
            "Epoch 472/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0722 - accuracy: 0.9888 - val_loss: 0.7839 - val_accuracy: 0.7852\n",
            "Epoch 473/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0750 - accuracy: 0.9814 - val_loss: 0.7769 - val_accuracy: 0.8000\n",
            "Epoch 474/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0764 - accuracy: 0.9796 - val_loss: 0.8111 - val_accuracy: 0.7852\n",
            "Epoch 475/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0724 - accuracy: 0.9796 - val_loss: 0.7912 - val_accuracy: 0.7926\n",
            "Epoch 476/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0732 - accuracy: 0.9796 - val_loss: 0.7666 - val_accuracy: 0.8000\n",
            "Epoch 477/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0739 - accuracy: 0.9758 - val_loss: 0.7945 - val_accuracy: 0.7778\n",
            "Epoch 478/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0729 - accuracy: 0.9833 - val_loss: 0.7858 - val_accuracy: 0.8074\n",
            "Epoch 479/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0715 - accuracy: 0.9833 - val_loss: 0.8239 - val_accuracy: 0.7778\n",
            "Epoch 480/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0708 - accuracy: 0.9814 - val_loss: 0.7942 - val_accuracy: 0.8074\n",
            "Epoch 481/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0726 - accuracy: 0.9814 - val_loss: 0.7777 - val_accuracy: 0.8000\n",
            "Epoch 482/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0743 - accuracy: 0.9777 - val_loss: 0.8136 - val_accuracy: 0.7778\n",
            "Epoch 483/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0724 - accuracy: 0.9814 - val_loss: 0.7869 - val_accuracy: 0.7926\n",
            "Epoch 484/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0707 - accuracy: 0.9833 - val_loss: 0.8010 - val_accuracy: 0.7778\n",
            "Epoch 485/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0712 - accuracy: 0.9833 - val_loss: 0.7661 - val_accuracy: 0.8000\n",
            "Epoch 486/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0721 - accuracy: 0.9814 - val_loss: 0.8395 - val_accuracy: 0.7556\n",
            "Epoch 487/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0694 - accuracy: 0.9870 - val_loss: 0.7969 - val_accuracy: 0.7778\n",
            "Epoch 488/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0726 - accuracy: 0.9851 - val_loss: 0.7816 - val_accuracy: 0.7926\n",
            "Epoch 489/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0681 - accuracy: 0.9851 - val_loss: 0.8091 - val_accuracy: 0.7926\n",
            "Epoch 490/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0674 - accuracy: 0.9851 - val_loss: 0.7950 - val_accuracy: 0.7704\n",
            "Epoch 491/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0688 - accuracy: 0.9833 - val_loss: 0.7947 - val_accuracy: 0.8074\n",
            "Epoch 492/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0688 - accuracy: 0.9796 - val_loss: 0.8027 - val_accuracy: 0.7852\n",
            "Epoch 493/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0664 - accuracy: 0.9851 - val_loss: 0.8025 - val_accuracy: 0.7926\n",
            "Epoch 494/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0662 - accuracy: 0.9833 - val_loss: 0.8012 - val_accuracy: 0.7778\n",
            "Epoch 495/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0673 - accuracy: 0.9833 - val_loss: 0.8198 - val_accuracy: 0.7778\n",
            "Epoch 496/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0692 - accuracy: 0.9870 - val_loss: 0.8004 - val_accuracy: 0.7704\n",
            "Epoch 497/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0664 - accuracy: 0.9796 - val_loss: 0.8168 - val_accuracy: 0.7852\n",
            "Epoch 498/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0675 - accuracy: 0.9851 - val_loss: 0.8085 - val_accuracy: 0.7778\n",
            "Epoch 499/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0661 - accuracy: 0.9851 - val_loss: 0.8004 - val_accuracy: 0.7926\n",
            "Epoch 500/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0685 - accuracy: 0.9777 - val_loss: 0.8199 - val_accuracy: 0.7926\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faabd3f4f40>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 데이터 로드\n",
        "data_path = '/content/week5_test.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# 입력 및 출력 변수 분리\n",
        "X = data[['GyroX', 'GyroY', 'GyroZ', 'Temperature', 'Heartbeat']].values\n",
        "y = data['Label'].values\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# 훈련 및 테스트 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 정규화\n",
        "X_train_mean = X_train.mean(axis=0)\n",
        "X_train_std = X_train.std(axis=0)\n",
        "X_train_normalized = (X_train - X_train_mean) / X_train_std\n",
        "X_test_normalized = (X_test - X_train_mean) / X_train_std\n",
        "\n",
        "# 입력 데이터 형태 조정\n",
        "X_train_reshaped = X_train_normalized.reshape((X_train_normalized.shape[0], X_train_normalized.shape[1], 1))\n",
        "X_test_reshaped = X_test_normalized.reshape((X_test_normalized.shape[0], X_test_normalized.shape[1], 1))\n",
        "\n",
        "# CNN-LSTM 모델 구성\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_normalized.shape[1], 1)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping 적용\n",
        "early_stopping = EarlyStopping(patience=3)\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_data=(X_test_reshaped, y_test), callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFMIHpzohIyR",
        "outputId": "4b6e7171-0b71-4cef-a42b-84da35d1dbed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "17/17 [==============================] - 3s 62ms/step - loss: 1.7438 - accuracy: 0.4312 - val_loss: 1.6275 - val_accuracy: 0.6370\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.6013 - accuracy: 0.5149 - val_loss: 1.4023 - val_accuracy: 0.6370\n",
            "Epoch 3/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.4551 - accuracy: 0.5149 - val_loss: 1.1943 - val_accuracy: 0.6370\n",
            "Epoch 4/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.3477 - accuracy: 0.5149 - val_loss: 1.1163 - val_accuracy: 0.6370\n",
            "Epoch 5/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.3037 - accuracy: 0.5149 - val_loss: 1.0809 - val_accuracy: 0.6370\n",
            "Epoch 6/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.2564 - accuracy: 0.5149 - val_loss: 1.0505 - val_accuracy: 0.6370\n",
            "Epoch 7/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.2179 - accuracy: 0.5149 - val_loss: 1.0210 - val_accuracy: 0.6444\n",
            "Epoch 8/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.1810 - accuracy: 0.5390 - val_loss: 0.9790 - val_accuracy: 0.6889\n",
            "Epoch 9/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.1355 - accuracy: 0.5725 - val_loss: 0.9409 - val_accuracy: 0.6963\n",
            "Epoch 10/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.0912 - accuracy: 0.5985 - val_loss: 0.8969 - val_accuracy: 0.7111\n",
            "Epoch 11/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.0424 - accuracy: 0.6152 - val_loss: 0.8733 - val_accuracy: 0.7333\n",
            "Epoch 12/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.9928 - accuracy: 0.6357 - val_loss: 0.8260 - val_accuracy: 0.7333\n",
            "Epoch 13/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.9549 - accuracy: 0.6487 - val_loss: 0.8044 - val_accuracy: 0.7407\n",
            "Epoch 14/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.9120 - accuracy: 0.6394 - val_loss: 0.7827 - val_accuracy: 0.7407\n",
            "Epoch 15/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.8819 - accuracy: 0.6691 - val_loss: 0.7576 - val_accuracy: 0.7630\n",
            "Epoch 16/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.8500 - accuracy: 0.7026 - val_loss: 0.7367 - val_accuracy: 0.7556\n",
            "Epoch 17/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.8322 - accuracy: 0.6933 - val_loss: 0.7269 - val_accuracy: 0.7481\n",
            "Epoch 18/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.8081 - accuracy: 0.6952 - val_loss: 0.6959 - val_accuracy: 0.7704\n",
            "Epoch 19/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7864 - accuracy: 0.7026 - val_loss: 0.6778 - val_accuracy: 0.7778\n",
            "Epoch 20/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7677 - accuracy: 0.7156 - val_loss: 0.6726 - val_accuracy: 0.8000\n",
            "Epoch 21/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7501 - accuracy: 0.7268 - val_loss: 0.6715 - val_accuracy: 0.7852\n",
            "Epoch 22/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7280 - accuracy: 0.7379 - val_loss: 0.6369 - val_accuracy: 0.8000\n",
            "Epoch 23/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.7194 - accuracy: 0.7472 - val_loss: 0.6303 - val_accuracy: 0.8074\n",
            "Epoch 24/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7111 - accuracy: 0.7472 - val_loss: 0.6132 - val_accuracy: 0.8222\n",
            "Epoch 25/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.7096 - accuracy: 0.7546 - val_loss: 0.6098 - val_accuracy: 0.8148\n",
            "Epoch 26/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7105 - accuracy: 0.7323 - val_loss: 0.6017 - val_accuracy: 0.7926\n",
            "Epoch 27/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6647 - accuracy: 0.7584 - val_loss: 0.5936 - val_accuracy: 0.8222\n",
            "Epoch 28/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6770 - accuracy: 0.7770 - val_loss: 0.5790 - val_accuracy: 0.8148\n",
            "Epoch 29/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6698 - accuracy: 0.7472 - val_loss: 0.5804 - val_accuracy: 0.8222\n",
            "Epoch 30/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6438 - accuracy: 0.7714 - val_loss: 0.5676 - val_accuracy: 0.8074\n",
            "Epoch 31/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6539 - accuracy: 0.7658 - val_loss: 0.5597 - val_accuracy: 0.8222\n",
            "Epoch 32/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6316 - accuracy: 0.7937 - val_loss: 0.5595 - val_accuracy: 0.8370\n",
            "Epoch 33/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6318 - accuracy: 0.7621 - val_loss: 0.5542 - val_accuracy: 0.8296\n",
            "Epoch 34/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6261 - accuracy: 0.7677 - val_loss: 0.5458 - val_accuracy: 0.8222\n",
            "Epoch 35/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6208 - accuracy: 0.7825 - val_loss: 0.5380 - val_accuracy: 0.8296\n",
            "Epoch 36/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6233 - accuracy: 0.7639 - val_loss: 0.5361 - val_accuracy: 0.8296\n",
            "Epoch 37/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6064 - accuracy: 0.7881 - val_loss: 0.5307 - val_accuracy: 0.8222\n",
            "Epoch 38/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5986 - accuracy: 0.7751 - val_loss: 0.5266 - val_accuracy: 0.8296\n",
            "Epoch 39/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5958 - accuracy: 0.7881 - val_loss: 0.5294 - val_accuracy: 0.8296\n",
            "Epoch 40/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6086 - accuracy: 0.7937 - val_loss: 0.5198 - val_accuracy: 0.8222\n",
            "Epoch 41/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5893 - accuracy: 0.7955 - val_loss: 0.5162 - val_accuracy: 0.8370\n",
            "Epoch 42/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5924 - accuracy: 0.7881 - val_loss: 0.5116 - val_accuracy: 0.8296\n",
            "Epoch 43/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5897 - accuracy: 0.7844 - val_loss: 0.5140 - val_accuracy: 0.8296\n",
            "Epoch 44/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5826 - accuracy: 0.7900 - val_loss: 0.5062 - val_accuracy: 0.8296\n",
            "Epoch 45/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5790 - accuracy: 0.7825 - val_loss: 0.5003 - val_accuracy: 0.8370\n",
            "Epoch 46/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5842 - accuracy: 0.7900 - val_loss: 0.4998 - val_accuracy: 0.8296\n",
            "Epoch 47/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5738 - accuracy: 0.8048 - val_loss: 0.5005 - val_accuracy: 0.8296\n",
            "Epoch 48/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5733 - accuracy: 0.8011 - val_loss: 0.5010 - val_accuracy: 0.8296\n",
            "Epoch 49/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5616 - accuracy: 0.7974 - val_loss: 0.4911 - val_accuracy: 0.8296\n",
            "Epoch 50/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5690 - accuracy: 0.7844 - val_loss: 0.4884 - val_accuracy: 0.8370\n",
            "Epoch 51/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5668 - accuracy: 0.7918 - val_loss: 0.4966 - val_accuracy: 0.8148\n",
            "Epoch 52/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5617 - accuracy: 0.7844 - val_loss: 0.4872 - val_accuracy: 0.8296\n",
            "Epoch 53/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5703 - accuracy: 0.7955 - val_loss: 0.4877 - val_accuracy: 0.8370\n",
            "Epoch 54/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5418 - accuracy: 0.8067 - val_loss: 0.4887 - val_accuracy: 0.8296\n",
            "Epoch 55/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5345 - accuracy: 0.8048 - val_loss: 0.4758 - val_accuracy: 0.8444\n",
            "Epoch 56/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5294 - accuracy: 0.8104 - val_loss: 0.4834 - val_accuracy: 0.8296\n",
            "Epoch 57/100\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5473 - accuracy: 0.8086 - val_loss: 0.4770 - val_accuracy: 0.8296\n",
            "Epoch 58/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5300 - accuracy: 0.7974 - val_loss: 0.4750 - val_accuracy: 0.8370\n",
            "Epoch 59/100\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5357 - accuracy: 0.8123 - val_loss: 0.4684 - val_accuracy: 0.8222\n",
            "Epoch 60/100\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5330 - accuracy: 0.8216 - val_loss: 0.4838 - val_accuracy: 0.8222\n",
            "Epoch 61/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5282 - accuracy: 0.8086 - val_loss: 0.4813 - val_accuracy: 0.8370\n",
            "Epoch 62/100\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5262 - accuracy: 0.8086 - val_loss: 0.4645 - val_accuracy: 0.8519\n",
            "Epoch 63/100\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5256 - accuracy: 0.8086 - val_loss: 0.4692 - val_accuracy: 0.8296\n",
            "Epoch 64/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5103 - accuracy: 0.8030 - val_loss: 0.4676 - val_accuracy: 0.8444\n",
            "Epoch 65/100\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5075 - accuracy: 0.8234 - val_loss: 0.4604 - val_accuracy: 0.8519\n",
            "Epoch 66/100\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5206 - accuracy: 0.8030 - val_loss: 0.4597 - val_accuracy: 0.8593\n",
            "Epoch 67/100\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5132 - accuracy: 0.8160 - val_loss: 0.4640 - val_accuracy: 0.8370\n",
            "Epoch 68/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5123 - accuracy: 0.8197 - val_loss: 0.4681 - val_accuracy: 0.8444\n",
            "Epoch 69/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5209 - accuracy: 0.8086 - val_loss: 0.4670 - val_accuracy: 0.8370\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faaafbe3970>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 데이터 로드\n",
        "data_path = '/content/week5_test.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# 입력 및 출력 변수 분리\n",
        "X = data[['GyroX', 'GyroY', 'GyroZ', 'Temperature', 'Heartbeat']].values\n",
        "y = data['Label'].values\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# 훈련 및 테스트 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 정규화\n",
        "X_train_mean = X_train.mean(axis=0)\n",
        "X_train_std = X_train.std(axis=0)\n",
        "X_train_normalized = (X_train - X_train_mean) / X_train_std\n",
        "X_test_normalized = (X_test - X_train_mean) / X_train_std\n",
        "\n",
        "# 입력 데이터 형태 조정\n",
        "X_train_reshaped = X_train_normalized.reshape((X_train_normalized.shape[0], X_train_normalized.shape[1], 1))\n",
        "X_test_reshaped = X_test_normalized.reshape((X_test_normalized.shape[0], X_test_normalized.shape[1], 1))\n",
        "\n",
        "# CNN-LSTM 모델 구성\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_normalized.shape[1], 1)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping 적용\n",
        "early_stopping = EarlyStopping(patience=3)\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(X_train_reshaped, y_train, epochs=500, batch_size=32, validation_data=(X_test_reshaped, y_test), callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17NEfbzfhWKO",
        "outputId": "2c64c93c-8540-44d0-9e0a-ed4b7f3dd1d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "17/17 [==============================] - 3s 37ms/step - loss: 1.7410 - accuracy: 0.4294 - val_loss: 1.6374 - val_accuracy: 0.6370\n",
            "Epoch 2/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.6060 - accuracy: 0.5149 - val_loss: 1.4231 - val_accuracy: 0.6370\n",
            "Epoch 3/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.4653 - accuracy: 0.5149 - val_loss: 1.2274 - val_accuracy: 0.6370\n",
            "Epoch 4/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.3513 - accuracy: 0.5149 - val_loss: 1.1209 - val_accuracy: 0.6370\n",
            "Epoch 5/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.2704 - accuracy: 0.5186 - val_loss: 1.0599 - val_accuracy: 0.6741\n",
            "Epoch 6/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.2078 - accuracy: 0.5725 - val_loss: 1.0026 - val_accuracy: 0.6963\n",
            "Epoch 7/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.1497 - accuracy: 0.6097 - val_loss: 0.9584 - val_accuracy: 0.7037\n",
            "Epoch 8/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.0999 - accuracy: 0.6283 - val_loss: 0.9037 - val_accuracy: 0.7037\n",
            "Epoch 9/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.0471 - accuracy: 0.6301 - val_loss: 0.8778 - val_accuracy: 0.7333\n",
            "Epoch 10/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.0016 - accuracy: 0.6357 - val_loss: 0.8502 - val_accuracy: 0.7259\n",
            "Epoch 11/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.9711 - accuracy: 0.6413 - val_loss: 0.8145 - val_accuracy: 0.7259\n",
            "Epoch 12/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.9300 - accuracy: 0.6450 - val_loss: 0.7986 - val_accuracy: 0.7259\n",
            "Epoch 13/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.9037 - accuracy: 0.6524 - val_loss: 0.7670 - val_accuracy: 0.7333\n",
            "Epoch 14/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.8732 - accuracy: 0.6636 - val_loss: 0.7664 - val_accuracy: 0.7556\n",
            "Epoch 15/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.8449 - accuracy: 0.6877 - val_loss: 0.7371 - val_accuracy: 0.7704\n",
            "Epoch 16/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.8215 - accuracy: 0.7007 - val_loss: 0.7110 - val_accuracy: 0.7630\n",
            "Epoch 17/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7899 - accuracy: 0.7138 - val_loss: 0.6973 - val_accuracy: 0.7778\n",
            "Epoch 18/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7766 - accuracy: 0.7249 - val_loss: 0.6914 - val_accuracy: 0.7778\n",
            "Epoch 19/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7653 - accuracy: 0.7342 - val_loss: 0.6771 - val_accuracy: 0.7852\n",
            "Epoch 20/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.7474 - accuracy: 0.7323 - val_loss: 0.6630 - val_accuracy: 0.7852\n",
            "Epoch 21/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7208 - accuracy: 0.7416 - val_loss: 0.6410 - val_accuracy: 0.7630\n",
            "Epoch 22/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7176 - accuracy: 0.7379 - val_loss: 0.6322 - val_accuracy: 0.7926\n",
            "Epoch 23/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7021 - accuracy: 0.7454 - val_loss: 0.6131 - val_accuracy: 0.7926\n",
            "Epoch 24/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6856 - accuracy: 0.7286 - val_loss: 0.6139 - val_accuracy: 0.7926\n",
            "Epoch 25/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6816 - accuracy: 0.7528 - val_loss: 0.6000 - val_accuracy: 0.8000\n",
            "Epoch 26/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6623 - accuracy: 0.7677 - val_loss: 0.5938 - val_accuracy: 0.8074\n",
            "Epoch 27/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6611 - accuracy: 0.7714 - val_loss: 0.5793 - val_accuracy: 0.8148\n",
            "Epoch 28/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6347 - accuracy: 0.7602 - val_loss: 0.5759 - val_accuracy: 0.8148\n",
            "Epoch 29/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6291 - accuracy: 0.7807 - val_loss: 0.5819 - val_accuracy: 0.8148\n",
            "Epoch 30/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6360 - accuracy: 0.7732 - val_loss: 0.5623 - val_accuracy: 0.8148\n",
            "Epoch 31/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6309 - accuracy: 0.7844 - val_loss: 0.5708 - val_accuracy: 0.8074\n",
            "Epoch 32/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6256 - accuracy: 0.7881 - val_loss: 0.5516 - val_accuracy: 0.8296\n",
            "Epoch 33/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6088 - accuracy: 0.7807 - val_loss: 0.5603 - val_accuracy: 0.8074\n",
            "Epoch 34/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6121 - accuracy: 0.7825 - val_loss: 0.5443 - val_accuracy: 0.8148\n",
            "Epoch 35/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5807 - accuracy: 0.7862 - val_loss: 0.5436 - val_accuracy: 0.8148\n",
            "Epoch 36/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5878 - accuracy: 0.7807 - val_loss: 0.5448 - val_accuracy: 0.8222\n",
            "Epoch 37/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5907 - accuracy: 0.8123 - val_loss: 0.5343 - val_accuracy: 0.8222\n",
            "Epoch 38/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5765 - accuracy: 0.8067 - val_loss: 0.5328 - val_accuracy: 0.8148\n",
            "Epoch 39/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5813 - accuracy: 0.7862 - val_loss: 0.5226 - val_accuracy: 0.8148\n",
            "Epoch 40/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5750 - accuracy: 0.7993 - val_loss: 0.5225 - val_accuracy: 0.8148\n",
            "Epoch 41/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5815 - accuracy: 0.7881 - val_loss: 0.5319 - val_accuracy: 0.8148\n",
            "Epoch 42/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5634 - accuracy: 0.7862 - val_loss: 0.5140 - val_accuracy: 0.8370\n",
            "Epoch 43/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5672 - accuracy: 0.8030 - val_loss: 0.5156 - val_accuracy: 0.8222\n",
            "Epoch 44/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5480 - accuracy: 0.8011 - val_loss: 0.5156 - val_accuracy: 0.8370\n",
            "Epoch 45/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5535 - accuracy: 0.8086 - val_loss: 0.5173 - val_accuracy: 0.8148\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faabd9a1030>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 데이터 로드\n",
        "data_path = '/content/week5_test.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# 입력 및 출력 변수 분리\n",
        "X = data[['GyroX', 'GyroY', 'GyroZ', 'Temperature', 'Heartbeat']].values\n",
        "y = data['Label'].values\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# 훈련 및 테스트 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 정규화\n",
        "X_train_mean = X_train.mean(axis=0)\n",
        "X_train_std = X_train.std(axis=0)\n",
        "X_train_normalized = (X_train - X_train_mean) / X_train_std\n",
        "X_test_normalized = (X_test - X_train_mean) / X_train_std\n",
        "\n",
        "# 입력 데이터 형태 조정\n",
        "X_train_reshaped = X_train_normalized.reshape((X_train_normalized.shape[0], X_train_normalized.shape[1], 1))\n",
        "X_test_reshaped = X_test_normalized.reshape((X_test_normalized.shape[0], X_test_normalized.shape[1], 1))\n",
        "\n",
        "# CNN-LSTM 모델 구성\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_normalized.shape[1], 1)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping 적용\n",
        "early_stopping = EarlyStopping(patience=3)\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(X_train_reshaped, y_train, epochs=500, batch_size=32, validation_data=(X_test_reshaped, y_test), callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c64c93c-8540-44d0-9e0a-ed4b7f3dd1d8",
        "id": "5PFti1LPigFz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "17/17 [==============================] - 3s 37ms/step - loss: 1.7410 - accuracy: 0.4294 - val_loss: 1.6374 - val_accuracy: 0.6370\n",
            "Epoch 2/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.6060 - accuracy: 0.5149 - val_loss: 1.4231 - val_accuracy: 0.6370\n",
            "Epoch 3/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.4653 - accuracy: 0.5149 - val_loss: 1.2274 - val_accuracy: 0.6370\n",
            "Epoch 4/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.3513 - accuracy: 0.5149 - val_loss: 1.1209 - val_accuracy: 0.6370\n",
            "Epoch 5/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.2704 - accuracy: 0.5186 - val_loss: 1.0599 - val_accuracy: 0.6741\n",
            "Epoch 6/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.2078 - accuracy: 0.5725 - val_loss: 1.0026 - val_accuracy: 0.6963\n",
            "Epoch 7/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.1497 - accuracy: 0.6097 - val_loss: 0.9584 - val_accuracy: 0.7037\n",
            "Epoch 8/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.0999 - accuracy: 0.6283 - val_loss: 0.9037 - val_accuracy: 0.7037\n",
            "Epoch 9/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.0471 - accuracy: 0.6301 - val_loss: 0.8778 - val_accuracy: 0.7333\n",
            "Epoch 10/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.0016 - accuracy: 0.6357 - val_loss: 0.8502 - val_accuracy: 0.7259\n",
            "Epoch 11/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.9711 - accuracy: 0.6413 - val_loss: 0.8145 - val_accuracy: 0.7259\n",
            "Epoch 12/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.9300 - accuracy: 0.6450 - val_loss: 0.7986 - val_accuracy: 0.7259\n",
            "Epoch 13/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.9037 - accuracy: 0.6524 - val_loss: 0.7670 - val_accuracy: 0.7333\n",
            "Epoch 14/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.8732 - accuracy: 0.6636 - val_loss: 0.7664 - val_accuracy: 0.7556\n",
            "Epoch 15/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.8449 - accuracy: 0.6877 - val_loss: 0.7371 - val_accuracy: 0.7704\n",
            "Epoch 16/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.8215 - accuracy: 0.7007 - val_loss: 0.7110 - val_accuracy: 0.7630\n",
            "Epoch 17/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7899 - accuracy: 0.7138 - val_loss: 0.6973 - val_accuracy: 0.7778\n",
            "Epoch 18/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7766 - accuracy: 0.7249 - val_loss: 0.6914 - val_accuracy: 0.7778\n",
            "Epoch 19/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7653 - accuracy: 0.7342 - val_loss: 0.6771 - val_accuracy: 0.7852\n",
            "Epoch 20/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.7474 - accuracy: 0.7323 - val_loss: 0.6630 - val_accuracy: 0.7852\n",
            "Epoch 21/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7208 - accuracy: 0.7416 - val_loss: 0.6410 - val_accuracy: 0.7630\n",
            "Epoch 22/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7176 - accuracy: 0.7379 - val_loss: 0.6322 - val_accuracy: 0.7926\n",
            "Epoch 23/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7021 - accuracy: 0.7454 - val_loss: 0.6131 - val_accuracy: 0.7926\n",
            "Epoch 24/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6856 - accuracy: 0.7286 - val_loss: 0.6139 - val_accuracy: 0.7926\n",
            "Epoch 25/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6816 - accuracy: 0.7528 - val_loss: 0.6000 - val_accuracy: 0.8000\n",
            "Epoch 26/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6623 - accuracy: 0.7677 - val_loss: 0.5938 - val_accuracy: 0.8074\n",
            "Epoch 27/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6611 - accuracy: 0.7714 - val_loss: 0.5793 - val_accuracy: 0.8148\n",
            "Epoch 28/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6347 - accuracy: 0.7602 - val_loss: 0.5759 - val_accuracy: 0.8148\n",
            "Epoch 29/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6291 - accuracy: 0.7807 - val_loss: 0.5819 - val_accuracy: 0.8148\n",
            "Epoch 30/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6360 - accuracy: 0.7732 - val_loss: 0.5623 - val_accuracy: 0.8148\n",
            "Epoch 31/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6309 - accuracy: 0.7844 - val_loss: 0.5708 - val_accuracy: 0.8074\n",
            "Epoch 32/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6256 - accuracy: 0.7881 - val_loss: 0.5516 - val_accuracy: 0.8296\n",
            "Epoch 33/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6088 - accuracy: 0.7807 - val_loss: 0.5603 - val_accuracy: 0.8074\n",
            "Epoch 34/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6121 - accuracy: 0.7825 - val_loss: 0.5443 - val_accuracy: 0.8148\n",
            "Epoch 35/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5807 - accuracy: 0.7862 - val_loss: 0.5436 - val_accuracy: 0.8148\n",
            "Epoch 36/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5878 - accuracy: 0.7807 - val_loss: 0.5448 - val_accuracy: 0.8222\n",
            "Epoch 37/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5907 - accuracy: 0.8123 - val_loss: 0.5343 - val_accuracy: 0.8222\n",
            "Epoch 38/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5765 - accuracy: 0.8067 - val_loss: 0.5328 - val_accuracy: 0.8148\n",
            "Epoch 39/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5813 - accuracy: 0.7862 - val_loss: 0.5226 - val_accuracy: 0.8148\n",
            "Epoch 40/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5750 - accuracy: 0.7993 - val_loss: 0.5225 - val_accuracy: 0.8148\n",
            "Epoch 41/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5815 - accuracy: 0.7881 - val_loss: 0.5319 - val_accuracy: 0.8148\n",
            "Epoch 42/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5634 - accuracy: 0.7862 - val_loss: 0.5140 - val_accuracy: 0.8370\n",
            "Epoch 43/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5672 - accuracy: 0.8030 - val_loss: 0.5156 - val_accuracy: 0.8222\n",
            "Epoch 44/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5480 - accuracy: 0.8011 - val_loss: 0.5156 - val_accuracy: 0.8370\n",
            "Epoch 45/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5535 - accuracy: 0.8086 - val_loss: 0.5173 - val_accuracy: 0.8148\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faabd9a1030>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 데이터 로드\n",
        "data_path = '/content/week5_test.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# 입력 및 출력 변수 분리\n",
        "X = data[['GyroX', 'GyroY', 'GyroZ', 'Temperature', 'Heartbeat']].values\n",
        "y = data['Label'].values\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# 훈련 및 테스트 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 정규화\n",
        "X_train_mean = X_train.mean(axis=0)\n",
        "X_train_std = X_train.std(axis=0)\n",
        "X_train_normalized = (X_train - X_train_mean) / X_train_std\n",
        "X_test_normalized = (X_test - X_train_mean) / X_train_std\n",
        "\n",
        "# 입력 데이터 형태 조정\n",
        "X_train_reshaped = X_train_normalized.reshape((X_train_normalized.shape[0], X_train_normalized.shape[1], 1))\n",
        "X_test_reshaped = X_test_normalized.reshape((X_test_normalized.shape[0], X_test_normalized.shape[1], 1))\n",
        "\n",
        "# CNN-LSTM 모델 구성\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_normalized.shape[1], 1)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping 적용\n",
        "early_stopping = EarlyStopping(patience=3)\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(X_train_reshaped, y_train, epochs=500, batch_size=32, validation_data=(X_test_reshaped, y_test), callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c64c93c-8540-44d0-9e0a-ed4b7f3dd1d8",
        "id": "_5SVe-SViQYz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "17/17 [==============================] - 3s 37ms/step - loss: 1.7410 - accuracy: 0.4294 - val_loss: 1.6374 - val_accuracy: 0.6370\n",
            "Epoch 2/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.6060 - accuracy: 0.5149 - val_loss: 1.4231 - val_accuracy: 0.6370\n",
            "Epoch 3/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.4653 - accuracy: 0.5149 - val_loss: 1.2274 - val_accuracy: 0.6370\n",
            "Epoch 4/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.3513 - accuracy: 0.5149 - val_loss: 1.1209 - val_accuracy: 0.6370\n",
            "Epoch 5/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.2704 - accuracy: 0.5186 - val_loss: 1.0599 - val_accuracy: 0.6741\n",
            "Epoch 6/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.2078 - accuracy: 0.5725 - val_loss: 1.0026 - val_accuracy: 0.6963\n",
            "Epoch 7/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.1497 - accuracy: 0.6097 - val_loss: 0.9584 - val_accuracy: 0.7037\n",
            "Epoch 8/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.0999 - accuracy: 0.6283 - val_loss: 0.9037 - val_accuracy: 0.7037\n",
            "Epoch 9/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.0471 - accuracy: 0.6301 - val_loss: 0.8778 - val_accuracy: 0.7333\n",
            "Epoch 10/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.0016 - accuracy: 0.6357 - val_loss: 0.8502 - val_accuracy: 0.7259\n",
            "Epoch 11/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.9711 - accuracy: 0.6413 - val_loss: 0.8145 - val_accuracy: 0.7259\n",
            "Epoch 12/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.9300 - accuracy: 0.6450 - val_loss: 0.7986 - val_accuracy: 0.7259\n",
            "Epoch 13/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.9037 - accuracy: 0.6524 - val_loss: 0.7670 - val_accuracy: 0.7333\n",
            "Epoch 14/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.8732 - accuracy: 0.6636 - val_loss: 0.7664 - val_accuracy: 0.7556\n",
            "Epoch 15/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.8449 - accuracy: 0.6877 - val_loss: 0.7371 - val_accuracy: 0.7704\n",
            "Epoch 16/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.8215 - accuracy: 0.7007 - val_loss: 0.7110 - val_accuracy: 0.7630\n",
            "Epoch 17/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7899 - accuracy: 0.7138 - val_loss: 0.6973 - val_accuracy: 0.7778\n",
            "Epoch 18/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7766 - accuracy: 0.7249 - val_loss: 0.6914 - val_accuracy: 0.7778\n",
            "Epoch 19/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7653 - accuracy: 0.7342 - val_loss: 0.6771 - val_accuracy: 0.7852\n",
            "Epoch 20/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.7474 - accuracy: 0.7323 - val_loss: 0.6630 - val_accuracy: 0.7852\n",
            "Epoch 21/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7208 - accuracy: 0.7416 - val_loss: 0.6410 - val_accuracy: 0.7630\n",
            "Epoch 22/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7176 - accuracy: 0.7379 - val_loss: 0.6322 - val_accuracy: 0.7926\n",
            "Epoch 23/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7021 - accuracy: 0.7454 - val_loss: 0.6131 - val_accuracy: 0.7926\n",
            "Epoch 24/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6856 - accuracy: 0.7286 - val_loss: 0.6139 - val_accuracy: 0.7926\n",
            "Epoch 25/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6816 - accuracy: 0.7528 - val_loss: 0.6000 - val_accuracy: 0.8000\n",
            "Epoch 26/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6623 - accuracy: 0.7677 - val_loss: 0.5938 - val_accuracy: 0.8074\n",
            "Epoch 27/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6611 - accuracy: 0.7714 - val_loss: 0.5793 - val_accuracy: 0.8148\n",
            "Epoch 28/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6347 - accuracy: 0.7602 - val_loss: 0.5759 - val_accuracy: 0.8148\n",
            "Epoch 29/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6291 - accuracy: 0.7807 - val_loss: 0.5819 - val_accuracy: 0.8148\n",
            "Epoch 30/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6360 - accuracy: 0.7732 - val_loss: 0.5623 - val_accuracy: 0.8148\n",
            "Epoch 31/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6309 - accuracy: 0.7844 - val_loss: 0.5708 - val_accuracy: 0.8074\n",
            "Epoch 32/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6256 - accuracy: 0.7881 - val_loss: 0.5516 - val_accuracy: 0.8296\n",
            "Epoch 33/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6088 - accuracy: 0.7807 - val_loss: 0.5603 - val_accuracy: 0.8074\n",
            "Epoch 34/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6121 - accuracy: 0.7825 - val_loss: 0.5443 - val_accuracy: 0.8148\n",
            "Epoch 35/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5807 - accuracy: 0.7862 - val_loss: 0.5436 - val_accuracy: 0.8148\n",
            "Epoch 36/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5878 - accuracy: 0.7807 - val_loss: 0.5448 - val_accuracy: 0.8222\n",
            "Epoch 37/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5907 - accuracy: 0.8123 - val_loss: 0.5343 - val_accuracy: 0.8222\n",
            "Epoch 38/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5765 - accuracy: 0.8067 - val_loss: 0.5328 - val_accuracy: 0.8148\n",
            "Epoch 39/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5813 - accuracy: 0.7862 - val_loss: 0.5226 - val_accuracy: 0.8148\n",
            "Epoch 40/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5750 - accuracy: 0.7993 - val_loss: 0.5225 - val_accuracy: 0.8148\n",
            "Epoch 41/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5815 - accuracy: 0.7881 - val_loss: 0.5319 - val_accuracy: 0.8148\n",
            "Epoch 42/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5634 - accuracy: 0.7862 - val_loss: 0.5140 - val_accuracy: 0.8370\n",
            "Epoch 43/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5672 - accuracy: 0.8030 - val_loss: 0.5156 - val_accuracy: 0.8222\n",
            "Epoch 44/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5480 - accuracy: 0.8011 - val_loss: 0.5156 - val_accuracy: 0.8370\n",
            "Epoch 45/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5535 - accuracy: 0.8086 - val_loss: 0.5173 - val_accuracy: 0.8148\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faabd9a1030>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 데이터 로드\n",
        "data_path = '/content/week5_test.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# 입력 및 출력 변수 분리\n",
        "X = data[['GyroX', 'GyroY', 'GyroZ', 'Temperature', 'Heartbeat']].values\n",
        "y = data['Label'].values\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# 훈련 및 테스트 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 정규화\n",
        "X_train_mean = X_train.mean(axis=0)\n",
        "X_train_std = X_train.std(axis=0)\n",
        "X_train_normalized = (X_train - X_train_mean) / X_train_std\n",
        "X_test_normalized = (X_test - X_train_mean) / X_train_std\n",
        "\n",
        "# 입력 데이터 형태 조정\n",
        "X_train_reshaped = X_train_normalized.reshape((X_train_normalized.shape[0], X_train_normalized.shape[1], 1))\n",
        "X_test_reshaped = X_test_normalized.reshape((X_test_normalized.shape[0], X_test_normalized.shape[1], 1))\n",
        "\n",
        "# CNN-LSTM 모델 구성\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_normalized.shape[1], 1)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping 적용\n",
        "early_stopping = EarlyStopping(patience=3)\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(X_train_reshaped, y_train, epochs=500, batch_size=32, validation_data=(X_test_reshaped, y_test), callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db511fd2-d7fd-430d-8096-a635b23e0085",
        "id": "cU1VHu6IiJU0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "17/17 [==============================] - 3s 38ms/step - loss: 1.7410 - accuracy: 0.4294 - val_loss: 1.6297 - val_accuracy: 0.6370\n",
            "Epoch 2/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.5989 - accuracy: 0.5149 - val_loss: 1.4093 - val_accuracy: 0.6370\n",
            "Epoch 3/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.4441 - accuracy: 0.5149 - val_loss: 1.1947 - val_accuracy: 0.6370\n",
            "Epoch 4/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.3301 - accuracy: 0.5149 - val_loss: 1.0904 - val_accuracy: 0.6370\n",
            "Epoch 5/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.2752 - accuracy: 0.5167 - val_loss: 1.0466 - val_accuracy: 0.6370\n",
            "Epoch 6/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.2202 - accuracy: 0.5279 - val_loss: 1.0112 - val_accuracy: 0.6667\n",
            "Epoch 7/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.1770 - accuracy: 0.5688 - val_loss: 0.9673 - val_accuracy: 0.6963\n",
            "Epoch 8/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.1257 - accuracy: 0.5874 - val_loss: 0.9154 - val_accuracy: 0.6963\n",
            "Epoch 9/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.0677 - accuracy: 0.6134 - val_loss: 0.8800 - val_accuracy: 0.7185\n",
            "Epoch 10/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.0119 - accuracy: 0.6413 - val_loss: 0.8314 - val_accuracy: 0.7333\n",
            "Epoch 11/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.9636 - accuracy: 0.6654 - val_loss: 0.8099 - val_accuracy: 0.7333\n",
            "Epoch 12/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.9308 - accuracy: 0.6822 - val_loss: 0.7857 - val_accuracy: 0.7333\n",
            "Epoch 13/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.8842 - accuracy: 0.7007 - val_loss: 0.7656 - val_accuracy: 0.7630\n",
            "Epoch 14/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.8632 - accuracy: 0.7156 - val_loss: 0.7467 - val_accuracy: 0.7704\n",
            "Epoch 15/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.8390 - accuracy: 0.7063 - val_loss: 0.7265 - val_accuracy: 0.7778\n",
            "Epoch 16/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.8251 - accuracy: 0.7100 - val_loss: 0.7203 - val_accuracy: 0.7852\n",
            "Epoch 17/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.7893 - accuracy: 0.7063 - val_loss: 0.6891 - val_accuracy: 0.7926\n",
            "Epoch 18/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7772 - accuracy: 0.7249 - val_loss: 0.6842 - val_accuracy: 0.8074\n",
            "Epoch 19/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7711 - accuracy: 0.7361 - val_loss: 0.6565 - val_accuracy: 0.7926\n",
            "Epoch 20/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7491 - accuracy: 0.7212 - val_loss: 0.6556 - val_accuracy: 0.8148\n",
            "Epoch 21/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7303 - accuracy: 0.7230 - val_loss: 0.6372 - val_accuracy: 0.7926\n",
            "Epoch 22/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7007 - accuracy: 0.7435 - val_loss: 0.6166 - val_accuracy: 0.8000\n",
            "Epoch 23/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6978 - accuracy: 0.7342 - val_loss: 0.6233 - val_accuracy: 0.8000\n",
            "Epoch 24/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6962 - accuracy: 0.7509 - val_loss: 0.6031 - val_accuracy: 0.8074\n",
            "Epoch 25/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6750 - accuracy: 0.7454 - val_loss: 0.5935 - val_accuracy: 0.8074\n",
            "Epoch 26/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6632 - accuracy: 0.7621 - val_loss: 0.5812 - val_accuracy: 0.8074\n",
            "Epoch 27/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.6516 - accuracy: 0.7677 - val_loss: 0.5832 - val_accuracy: 0.8370\n",
            "Epoch 28/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6343 - accuracy: 0.7658 - val_loss: 0.5705 - val_accuracy: 0.8296\n",
            "Epoch 29/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6434 - accuracy: 0.7639 - val_loss: 0.5571 - val_accuracy: 0.8296\n",
            "Epoch 30/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6149 - accuracy: 0.7862 - val_loss: 0.5583 - val_accuracy: 0.8519\n",
            "Epoch 31/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6207 - accuracy: 0.7677 - val_loss: 0.5404 - val_accuracy: 0.8222\n",
            "Epoch 32/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6067 - accuracy: 0.7807 - val_loss: 0.5482 - val_accuracy: 0.8222\n",
            "Epoch 33/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6102 - accuracy: 0.7918 - val_loss: 0.5431 - val_accuracy: 0.8370\n",
            "Epoch 34/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6016 - accuracy: 0.7770 - val_loss: 0.5372 - val_accuracy: 0.8370\n",
            "Epoch 35/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6163 - accuracy: 0.7770 - val_loss: 0.5227 - val_accuracy: 0.8222\n",
            "Epoch 36/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5867 - accuracy: 0.7751 - val_loss: 0.5240 - val_accuracy: 0.8222\n",
            "Epoch 37/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5891 - accuracy: 0.7862 - val_loss: 0.5214 - val_accuracy: 0.8370\n",
            "Epoch 38/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5829 - accuracy: 0.7937 - val_loss: 0.5310 - val_accuracy: 0.8370\n",
            "Epoch 39/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5838 - accuracy: 0.7918 - val_loss: 0.5190 - val_accuracy: 0.8370\n",
            "Epoch 40/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5790 - accuracy: 0.7937 - val_loss: 0.5139 - val_accuracy: 0.8519\n",
            "Epoch 41/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5806 - accuracy: 0.7900 - val_loss: 0.5127 - val_accuracy: 0.8444\n",
            "Epoch 42/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5662 - accuracy: 0.7955 - val_loss: 0.5068 - val_accuracy: 0.8370\n",
            "Epoch 43/500\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5621 - accuracy: 0.7862 - val_loss: 0.5080 - val_accuracy: 0.8519\n",
            "Epoch 44/500\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5576 - accuracy: 0.8011 - val_loss: 0.5031 - val_accuracy: 0.8519\n",
            "Epoch 45/500\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5601 - accuracy: 0.7937 - val_loss: 0.5021 - val_accuracy: 0.8444\n",
            "Epoch 46/500\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.5529 - accuracy: 0.7918 - val_loss: 0.4954 - val_accuracy: 0.8444\n",
            "Epoch 47/500\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.5473 - accuracy: 0.8104 - val_loss: 0.4971 - val_accuracy: 0.8444\n",
            "Epoch 48/500\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.5494 - accuracy: 0.7974 - val_loss: 0.4869 - val_accuracy: 0.8519\n",
            "Epoch 49/500\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.5572 - accuracy: 0.7937 - val_loss: 0.4953 - val_accuracy: 0.8370\n",
            "Epoch 50/500\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 0.5363 - accuracy: 0.7955 - val_loss: 0.4919 - val_accuracy: 0.8519\n",
            "Epoch 51/500\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 0.5412 - accuracy: 0.8104 - val_loss: 0.4823 - val_accuracy: 0.8593\n",
            "Epoch 52/500\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.5329 - accuracy: 0.8030 - val_loss: 0.4796 - val_accuracy: 0.8593\n",
            "Epoch 53/500\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.5338 - accuracy: 0.8048 - val_loss: 0.4806 - val_accuracy: 0.8519\n",
            "Epoch 54/500\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5287 - accuracy: 0.8123 - val_loss: 0.4827 - val_accuracy: 0.8519\n",
            "Epoch 55/500\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5347 - accuracy: 0.8160 - val_loss: 0.4799 - val_accuracy: 0.8444\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faaaeb4c280>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
        "\n",
        "# 데이터 로드\n",
        "data_path = '/content/week5_test.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# 입력 및 출력 변수 분리\n",
        "X = data[['GyroX', 'GyroY', 'GyroZ', 'Temperature', 'Heartbeat']].values\n",
        "y = data['Label'].values\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# 훈련 및 테스트 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 증강을 위한 TimeseriesGenerator 생성\n",
        "window_size = 10\n",
        "batch_size = 32\n",
        "train_data_generator = TimeseriesGenerator(X_train, y_train, length=window_size, sampling_rate=1, batch_size=batch_size)\n",
        "test_data_generator = TimeseriesGenerator(X_test, y_test, length=window_size, sampling_rate=1, batch_size=batch_size)\n",
        "\n",
        "# CNN-LSTM 모델 구성\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(window_size, X_train.shape[1])))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping 적용\n",
        "early_stopping = EarlyStopping(patience=3)\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(train_data_generator, epochs=100, validation_data=test_data_generator, callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2vuaC7DiAu-",
        "outputId": "763cca5a-b809-4690-e7f8-635b8a8d425d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "17/17 [==============================] - 4s 84ms/step - loss: 1.5893 - accuracy: 0.4167 - val_loss: 1.2446 - val_accuracy: 0.6480\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 1.4177 - accuracy: 0.5170 - val_loss: 1.2297 - val_accuracy: 0.6480\n",
            "Epoch 3/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 1.3848 - accuracy: 0.5170 - val_loss: 1.2011 - val_accuracy: 0.6480\n",
            "Epoch 4/100\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 1.3618 - accuracy: 0.5152 - val_loss: 1.1966 - val_accuracy: 0.6480\n",
            "Epoch 5/100\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 1.3543 - accuracy: 0.5170 - val_loss: 1.2104 - val_accuracy: 0.6480\n",
            "Epoch 6/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 1.3355 - accuracy: 0.5170 - val_loss: 1.2067 - val_accuracy: 0.6480\n",
            "Epoch 7/100\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 1.3259 - accuracy: 0.5152 - val_loss: 1.2157 - val_accuracy: 0.6480\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faaaf1bc370>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
        "\n",
        "# 데이터 로드\n",
        "data_path = '/content/week5_test.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# 입력 및 출력 변수 분리\n",
        "X = data[['GyroX', 'GyroY', 'GyroZ', 'Temperature', 'Heartbeat']].values\n",
        "y = data['Label'].values\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# 훈련 및 테스트 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 증강을 위한 TimeseriesGenerator 생성\n",
        "window_size = 10\n",
        "batch_size = 32\n",
        "train_data_generator = TimeseriesGenerator(X_train, y_train, length=window_size, sampling_rate=1, batch_size=batch_size)\n",
        "test_data_generator = TimeseriesGenerator(X_test, y_test, length=window_size, sampling_rate=1, batch_size=batch_size)\n",
        "\n",
        "# CNN-LSTM 모델 구성\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(window_size, X_train.shape[1])))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping 적용\n",
        "early_stopping = EarlyStopping(patience=3)\n",
        "\n",
        "# ReduceLROnPlateau 적용\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=2)\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(train_data_generator, epochs=100, validation_data=test_data_generator, callbacks=[early_stopping, reduce_lr])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zlp7ndGiC1H",
        "outputId": "009f76ed-02e9-4639-bc3f-0a30d2db8f01"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "17/17 [==============================] - 3s 40ms/step - loss: 1.4995 - accuracy: 0.4792 - val_loss: 1.2961 - val_accuracy: 0.6480 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 1.3976 - accuracy: 0.5170 - val_loss: 1.2753 - val_accuracy: 0.6480 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 1.3702 - accuracy: 0.5189 - val_loss: 1.2697 - val_accuracy: 0.6480 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 1.3371 - accuracy: 0.5170 - val_loss: 1.2516 - val_accuracy: 0.6480 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.3411 - accuracy: 0.5208 - val_loss: 1.2338 - val_accuracy: 0.6480 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 1.3138 - accuracy: 0.5170 - val_loss: 1.2339 - val_accuracy: 0.6480 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 1.3074 - accuracy: 0.5170 - val_loss: 1.2568 - val_accuracy: 0.6480 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 1.2939 - accuracy: 0.5284 - val_loss: 1.2541 - val_accuracy: 0.6480 - lr: 1.0000e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faaaf1e0fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten, concatenate\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 데이터 로드\n",
        "data_path = '/content/week5_test.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# 입력 및 출력 변수 분리\n",
        "X_gyro = data[['GyroX', 'GyroY', 'GyroZ']].values\n",
        "X_other = data[['Temperature', 'Heartbeat']].values\n",
        "y = data['Label'].values\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# 훈련 및 테스트 데이터 분할\n",
        "X_gyro_train, X_gyro_test, X_other_train, X_other_test, y_train, y_test = train_test_split(X_gyro, X_other, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# CNN 입력 데이터 형태 조정\n",
        "X_gyro_train_reshaped = X_gyro_train.reshape((X_gyro_train.shape[0], X_gyro_train.shape[1], 1))\n",
        "X_gyro_test_reshaped = X_gyro_test.reshape((X_gyro_test.shape[0], X_gyro_test.shape[1], 1))\n",
        "\n",
        "# LSTM 입력 데이터 형태 조정\n",
        "X_other_train_reshaped = X_other_train.reshape((X_other_train.shape[0], X_other_train.shape[1], 1))\n",
        "X_other_test_reshaped = X_other_test.reshape((X_other_test.shape[0], X_other_test.shape[1], 1))\n",
        "\n",
        "# CNN 모델 구성\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_gyro_train.shape[1], 1)))\n",
        "cnn_model.add(MaxPooling1D(pool_size=1))\n",
        "cnn_model.add(Flatten())\n",
        "\n",
        "# LSTM 모델 구성\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(50, input_shape=(X_other_train.shape[1], 1)))\n",
        "\n",
        "# 모델 병합\n",
        "combined_model = Sequential()\n",
        "combined_model.add(cnn_model)\n",
        "combined_model.add(lstm_model)\n",
        "combined_model.add(Flatten())\n",
        "combined_model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "combined_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "combined_model.fit([X_gyro_train_reshaped, X_other_train_reshaped], y_train, epochs=10, batch_size=32, validation_data=([X_gyro_test_reshaped, X_other_test_reshaped], y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "6mYAHrfqj96b",
        "outputId": "0173c792-fa5e-43df-8d9b-26e98e1c6c2d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-991532c20f45>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# 모델 훈련\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mcombined_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_gyro_train_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_other_train_reshaped\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_gyro_test_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_other_test_reshaped\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"sequential_24\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 3, 1) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 2, 1) dtype=float32>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten, Input, concatenate\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 데이터 로드\n",
        "data_path = '/content/week5_test.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# 입력 및 출력 변수 분리\n",
        "X_gyro = data[['GyroX', 'GyroY', 'GyroZ']].values\n",
        "X_other = data[['Temperature', 'Heartbeat']].values\n",
        "y = data['Label'].values\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# 훈련 및 테스트 데이터 분할\n",
        "X_gyro_train, X_gyro_test, X_other_train, X_other_test, y_train, y_test = train_test_split(X_gyro, X_other, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# 입력 데이터 형태 조정\n",
        "X_gyro_train_reshaped = X_gyro_train.reshape((X_gyro_train.shape[0], X_gyro_train.shape[1], 1))\n",
        "X_gyro_test_reshaped = X_gyro_test.reshape((X_gyro_test.shape[0], X_gyro_test.shape[1], 1))\n",
        "X_other_train_reshaped = X_other_train.reshape((X_other_train.shape[0], X_other_train.shape[1], 1))\n",
        "X_other_test_reshaped = X_other_test.reshape((X_other_test.shape[0], X_other_test.shape[1], 1))\n",
        "\n",
        "# CNN 모델 구성\n",
        "cnn_input = Input(shape=(X_gyro_train.shape[1], 1))\n",
        "cnn_output = Conv1D(filters=64, kernel_size=3, activation='relu')(cnn_input)\n",
        "cnn_output = MaxPooling1D(pool_size=1)(cnn_output)\n",
        "cnn_output = Flatten()(cnn_output)\n",
        "cnn_model = Model(inputs=cnn_input, outputs=cnn_output)\n",
        "\n",
        "# LSTM 모델 구성\n",
        "lstm_input = Input(shape=(X_other_train.shape[1], 1))\n",
        "lstm_output = LSTM(50)(lstm_input)\n",
        "lstm_model = Model(inputs=lstm_input, outputs=lstm_output)\n",
        "\n",
        "# 모델 병합\n",
        "concatenated = concatenate([cnn_model.output, lstm_model.output])\n",
        "output = Dense(num_classes, activation='softmax')(concatenated)\n",
        "combined_model = Model(inputs=[cnn_model.input, lstm_model.input], outputs=output)\n",
        "\n",
        "# 모델 컴파일\n",
        "combined_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "combined_model.fit([X_gyro_train_reshaped, X_other_train_reshaped], y_train, epochs=100, batch_size=32, validation_data=([X_gyro_test_reshaped, X_other_test_reshaped], y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzmeYeUntVeE",
        "outputId": "2bcf297b-4eb6-4f3a-d4fa-9fcc3d47740b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "17/17 [==============================] - 3s 70ms/step - loss: 1.6173 - accuracy: 0.4275 - val_loss: 1.1396 - val_accuracy: 0.6741\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.2918 - accuracy: 0.5297 - val_loss: 1.0267 - val_accuracy: 0.6815\n",
            "Epoch 3/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.1761 - accuracy: 0.5725 - val_loss: 0.9554 - val_accuracy: 0.6815\n",
            "Epoch 4/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.0974 - accuracy: 0.5874 - val_loss: 0.9039 - val_accuracy: 0.6889\n",
            "Epoch 5/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.0380 - accuracy: 0.5967 - val_loss: 0.8603 - val_accuracy: 0.7037\n",
            "Epoch 6/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.9932 - accuracy: 0.6245 - val_loss: 0.8333 - val_accuracy: 0.7185\n",
            "Epoch 7/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.9515 - accuracy: 0.6506 - val_loss: 0.8031 - val_accuracy: 0.7111\n",
            "Epoch 8/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.9149 - accuracy: 0.6561 - val_loss: 0.7796 - val_accuracy: 0.6889\n",
            "Epoch 9/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.8817 - accuracy: 0.6877 - val_loss: 0.7615 - val_accuracy: 0.7185\n",
            "Epoch 10/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.8573 - accuracy: 0.7119 - val_loss: 0.7422 - val_accuracy: 0.7111\n",
            "Epoch 11/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.8350 - accuracy: 0.6914 - val_loss: 0.7308 - val_accuracy: 0.7407\n",
            "Epoch 12/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.8118 - accuracy: 0.7546 - val_loss: 0.7096 - val_accuracy: 0.7630\n",
            "Epoch 13/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7984 - accuracy: 0.7119 - val_loss: 0.7011 - val_accuracy: 0.7481\n",
            "Epoch 14/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7811 - accuracy: 0.7658 - val_loss: 0.6986 - val_accuracy: 0.7704\n",
            "Epoch 15/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7625 - accuracy: 0.7621 - val_loss: 0.6812 - val_accuracy: 0.7630\n",
            "Epoch 16/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7517 - accuracy: 0.7639 - val_loss: 0.6880 - val_accuracy: 0.7407\n",
            "Epoch 17/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7389 - accuracy: 0.7658 - val_loss: 0.6629 - val_accuracy: 0.7630\n",
            "Epoch 18/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7256 - accuracy: 0.7695 - val_loss: 0.6679 - val_accuracy: 0.7407\n",
            "Epoch 19/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.7140 - accuracy: 0.7677 - val_loss: 0.6522 - val_accuracy: 0.7630\n",
            "Epoch 20/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.7019 - accuracy: 0.7714 - val_loss: 0.6472 - val_accuracy: 0.7630\n",
            "Epoch 21/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6925 - accuracy: 0.7602 - val_loss: 0.6464 - val_accuracy: 0.7481\n",
            "Epoch 22/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6819 - accuracy: 0.7677 - val_loss: 0.6289 - val_accuracy: 0.7630\n",
            "Epoch 23/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6690 - accuracy: 0.7677 - val_loss: 0.6345 - val_accuracy: 0.7630\n",
            "Epoch 24/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6617 - accuracy: 0.7714 - val_loss: 0.6295 - val_accuracy: 0.7630\n",
            "Epoch 25/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6586 - accuracy: 0.7844 - val_loss: 0.6260 - val_accuracy: 0.7630\n",
            "Epoch 26/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6527 - accuracy: 0.7695 - val_loss: 0.6155 - val_accuracy: 0.7704\n",
            "Epoch 27/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6431 - accuracy: 0.7788 - val_loss: 0.6189 - val_accuracy: 0.7704\n",
            "Epoch 28/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.7751 - val_loss: 0.6230 - val_accuracy: 0.7704\n",
            "Epoch 29/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6314 - accuracy: 0.7844 - val_loss: 0.6058 - val_accuracy: 0.7778\n",
            "Epoch 30/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6272 - accuracy: 0.7714 - val_loss: 0.6043 - val_accuracy: 0.7704\n",
            "Epoch 31/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6212 - accuracy: 0.7844 - val_loss: 0.5999 - val_accuracy: 0.7778\n",
            "Epoch 32/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6170 - accuracy: 0.7825 - val_loss: 0.6137 - val_accuracy: 0.7630\n",
            "Epoch 33/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6167 - accuracy: 0.7881 - val_loss: 0.5988 - val_accuracy: 0.7778\n",
            "Epoch 34/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.6005 - accuracy: 0.7881 - val_loss: 0.6064 - val_accuracy: 0.7704\n",
            "Epoch 35/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5989 - accuracy: 0.7807 - val_loss: 0.5894 - val_accuracy: 0.7778\n",
            "Epoch 36/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5960 - accuracy: 0.7825 - val_loss: 0.6009 - val_accuracy: 0.7704\n",
            "Epoch 37/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5890 - accuracy: 0.7881 - val_loss: 0.5984 - val_accuracy: 0.7704\n",
            "Epoch 38/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5841 - accuracy: 0.7862 - val_loss: 0.5921 - val_accuracy: 0.7778\n",
            "Epoch 39/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5830 - accuracy: 0.7825 - val_loss: 0.5915 - val_accuracy: 0.7778\n",
            "Epoch 40/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5816 - accuracy: 0.7844 - val_loss: 0.5984 - val_accuracy: 0.7704\n",
            "Epoch 41/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5748 - accuracy: 0.7825 - val_loss: 0.5876 - val_accuracy: 0.7778\n",
            "Epoch 42/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5751 - accuracy: 0.7900 - val_loss: 0.5822 - val_accuracy: 0.7852\n",
            "Epoch 43/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5682 - accuracy: 0.7807 - val_loss: 0.5853 - val_accuracy: 0.7926\n",
            "Epoch 44/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5652 - accuracy: 0.7900 - val_loss: 0.5884 - val_accuracy: 0.7778\n",
            "Epoch 45/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5620 - accuracy: 0.7862 - val_loss: 0.5859 - val_accuracy: 0.7704\n",
            "Epoch 46/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5566 - accuracy: 0.7955 - val_loss: 0.5868 - val_accuracy: 0.7778\n",
            "Epoch 47/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5558 - accuracy: 0.7955 - val_loss: 0.5803 - val_accuracy: 0.7926\n",
            "Epoch 48/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5524 - accuracy: 0.7844 - val_loss: 0.5917 - val_accuracy: 0.7852\n",
            "Epoch 49/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5496 - accuracy: 0.7900 - val_loss: 0.5777 - val_accuracy: 0.7778\n",
            "Epoch 50/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5511 - accuracy: 0.7881 - val_loss: 0.5640 - val_accuracy: 0.7926\n",
            "Epoch 51/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5458 - accuracy: 0.7881 - val_loss: 0.5824 - val_accuracy: 0.7852\n",
            "Epoch 52/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5472 - accuracy: 0.7900 - val_loss: 0.5736 - val_accuracy: 0.7926\n",
            "Epoch 53/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5421 - accuracy: 0.7881 - val_loss: 0.5764 - val_accuracy: 0.7852\n",
            "Epoch 54/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5404 - accuracy: 0.8011 - val_loss: 0.5637 - val_accuracy: 0.8000\n",
            "Epoch 55/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5334 - accuracy: 0.7900 - val_loss: 0.5731 - val_accuracy: 0.7852\n",
            "Epoch 56/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5347 - accuracy: 0.7918 - val_loss: 0.5546 - val_accuracy: 0.7926\n",
            "Epoch 57/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5404 - accuracy: 0.7937 - val_loss: 0.5795 - val_accuracy: 0.7852\n",
            "Epoch 58/100\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5293 - accuracy: 0.7918 - val_loss: 0.5515 - val_accuracy: 0.8000\n",
            "Epoch 59/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5295 - accuracy: 0.7918 - val_loss: 0.5525 - val_accuracy: 0.7926\n",
            "Epoch 60/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5241 - accuracy: 0.7937 - val_loss: 0.5659 - val_accuracy: 0.7926\n",
            "Epoch 61/100\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5226 - accuracy: 0.7955 - val_loss: 0.5623 - val_accuracy: 0.8000\n",
            "Epoch 62/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5207 - accuracy: 0.7993 - val_loss: 0.5565 - val_accuracy: 0.8000\n",
            "Epoch 63/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5191 - accuracy: 0.7955 - val_loss: 0.5603 - val_accuracy: 0.7926\n",
            "Epoch 64/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5159 - accuracy: 0.8011 - val_loss: 0.5526 - val_accuracy: 0.8074\n",
            "Epoch 65/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.5133 - accuracy: 0.8067 - val_loss: 0.5402 - val_accuracy: 0.8074\n",
            "Epoch 66/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5143 - accuracy: 0.7974 - val_loss: 0.5551 - val_accuracy: 0.8000\n",
            "Epoch 67/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.5103 - accuracy: 0.8067 - val_loss: 0.5499 - val_accuracy: 0.8074\n",
            "Epoch 68/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5104 - accuracy: 0.7955 - val_loss: 0.5416 - val_accuracy: 0.8000\n",
            "Epoch 69/100\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5089 - accuracy: 0.8048 - val_loss: 0.5415 - val_accuracy: 0.8074\n",
            "Epoch 70/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5109 - accuracy: 0.7955 - val_loss: 0.5482 - val_accuracy: 0.8000\n",
            "Epoch 71/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5072 - accuracy: 0.8048 - val_loss: 0.5428 - val_accuracy: 0.7926\n",
            "Epoch 72/100\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5011 - accuracy: 0.8030 - val_loss: 0.5523 - val_accuracy: 0.8000\n",
            "Epoch 73/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5007 - accuracy: 0.8011 - val_loss: 0.5380 - val_accuracy: 0.8074\n",
            "Epoch 74/100\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.5043 - accuracy: 0.8030 - val_loss: 0.5396 - val_accuracy: 0.8000\n",
            "Epoch 75/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5001 - accuracy: 0.8030 - val_loss: 0.5310 - val_accuracy: 0.8000\n",
            "Epoch 76/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5006 - accuracy: 0.8104 - val_loss: 0.5551 - val_accuracy: 0.7926\n",
            "Epoch 77/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5036 - accuracy: 0.8048 - val_loss: 0.5362 - val_accuracy: 0.8074\n",
            "Epoch 78/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4947 - accuracy: 0.8067 - val_loss: 0.5324 - val_accuracy: 0.8074\n",
            "Epoch 79/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4919 - accuracy: 0.8104 - val_loss: 0.5348 - val_accuracy: 0.8074\n",
            "Epoch 80/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4922 - accuracy: 0.8067 - val_loss: 0.5332 - val_accuracy: 0.8074\n",
            "Epoch 81/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4929 - accuracy: 0.8030 - val_loss: 0.5386 - val_accuracy: 0.8000\n",
            "Epoch 82/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4905 - accuracy: 0.8067 - val_loss: 0.5295 - val_accuracy: 0.8074\n",
            "Epoch 83/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4887 - accuracy: 0.8104 - val_loss: 0.5330 - val_accuracy: 0.8000\n",
            "Epoch 84/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.8030 - val_loss: 0.5469 - val_accuracy: 0.7926\n",
            "Epoch 85/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4895 - accuracy: 0.7937 - val_loss: 0.5257 - val_accuracy: 0.8074\n",
            "Epoch 86/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.8104 - val_loss: 0.5352 - val_accuracy: 0.8000\n",
            "Epoch 87/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4834 - accuracy: 0.8104 - val_loss: 0.5278 - val_accuracy: 0.8074\n",
            "Epoch 88/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4854 - accuracy: 0.8086 - val_loss: 0.5255 - val_accuracy: 0.8074\n",
            "Epoch 89/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4812 - accuracy: 0.8048 - val_loss: 0.5392 - val_accuracy: 0.8074\n",
            "Epoch 90/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4824 - accuracy: 0.8030 - val_loss: 0.5233 - val_accuracy: 0.8074\n",
            "Epoch 91/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4826 - accuracy: 0.8067 - val_loss: 0.5308 - val_accuracy: 0.8074\n",
            "Epoch 92/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4820 - accuracy: 0.8048 - val_loss: 0.5253 - val_accuracy: 0.8074\n",
            "Epoch 93/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4802 - accuracy: 0.8048 - val_loss: 0.5331 - val_accuracy: 0.8000\n",
            "Epoch 94/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4789 - accuracy: 0.8141 - val_loss: 0.5222 - val_accuracy: 0.8074\n",
            "Epoch 95/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4783 - accuracy: 0.8067 - val_loss: 0.5258 - val_accuracy: 0.8074\n",
            "Epoch 96/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4768 - accuracy: 0.8086 - val_loss: 0.5307 - val_accuracy: 0.8000\n",
            "Epoch 97/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4762 - accuracy: 0.8104 - val_loss: 0.5211 - val_accuracy: 0.8000\n",
            "Epoch 98/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4740 - accuracy: 0.8104 - val_loss: 0.5225 - val_accuracy: 0.8074\n",
            "Epoch 99/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.4758 - accuracy: 0.8104 - val_loss: 0.5287 - val_accuracy: 0.8074\n",
            "Epoch 100/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4769 - accuracy: 0.8086 - val_loss: 0.5205 - val_accuracy: 0.8222\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faa9feaa320>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten, Input, concatenate\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 데이터 로드\n",
        "data_path = '/content/week5_test.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# 입력 및 출력 변수 분리\n",
        "X_gyro = data[['GyroX', 'GyroY', 'GyroZ']].values\n",
        "X_other = data[['Temperature', 'Heartbeat']].values\n",
        "y = data['Label'].values\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# 훈련 및 테스트 데이터 분할\n",
        "X_gyro_train, X_gyro_test, X_other_train, X_other_test, y_train, y_test = train_test_split(X_gyro, X_other, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# 입력 데이터 형태 조정\n",
        "X_gyro_train_reshaped = X_gyro_train.reshape((X_gyro_train.shape[0], X_gyro_train.shape[1], 1))\n",
        "X_gyro_test_reshaped = X_gyro_test.reshape((X_gyro_test.shape[0], X_gyro_test.shape[1], 1))\n",
        "X_other_train_reshaped = X_other_train.reshape((X_other_train.shape[0], X_other_train.shape[1], 1))\n",
        "X_other_test_reshaped = X_other_test.reshape((X_other_test.shape[0], X_other_test.shape[1], 1))\n",
        "\n",
        "# LSTM 모델 구성\n",
        "lstm_input = Input(shape=(X_gyro_train.shape[1], 1))\n",
        "lstm_output = LSTM(50)(lstm_input)\n",
        "lstm_model = Model(inputs=lstm_input, outputs=lstm_output)\n",
        "\n",
        "# CNN 모델 구성\n",
        "cnn_input = Input(shape=(X_other_train.shape[1], 1))\n",
        "cnn_output = Conv1D(filters=64, kernel_size=2, activation='relu')(cnn_input)\n",
        "cnn_output = MaxPooling1D(pool_size=2)(cnn_output)\n",
        "cnn_output = Flatten()(cnn_output)\n",
        "cnn_model = Model(inputs=cnn_input, outputs=cnn_output)\n",
        "\n",
        "# 모델 병합\n",
        "concatenated = concatenate([lstm_model.output, cnn_model.output])\n",
        "output = Dense(num_classes, activation='softmax')(concatenated)\n",
        "combined_model = Model(inputs=[lstm_model.input, cnn_model.input], outputs=output)\n",
        "\n",
        "# 모델 컴파일\n",
        "combined_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "combined_model.fit([X_gyro_train_reshaped, X_other_train_reshaped], y_train, epochs=10, batch_size=32, validation_data=([X_gyro_test_reshaped, X_other_test_reshaped], y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "tCpDl2L9v5-X",
        "outputId": "46976c6e-657e-46c8-e432-941d7f49a65f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-13e70efcd32b>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mcnn_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_other_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mcnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mcnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mcnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mcnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcnn_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcnn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mpool2d\u001b[0;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[1;32m   6521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"max\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6523\u001b[0;31m         x = tf.compat.v1.nn.max_pool(\n\u001b[0m\u001b[1;32m   6524\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf_data_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6525\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"max_pooling1d_23\" (type MaxPooling1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling1d_23/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 1, 1], padding=\"VALID\", strides=[1, 2, 1, 1]](max_pooling1d_23/ExpandDims)' with input shapes: [?,1,1,64].\n\nCall arguments received by layer \"max_pooling1d_23\" (type MaxPooling1D):\n  • inputs=tf.Tensor(shape=(None, 1, 64), dtype=float32)"
          ]
        }
      ]
    }
  ]
}